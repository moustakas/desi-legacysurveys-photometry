#!/usr/bin/env python3

"""Match data release redshift catalogs against the original photometric
(target) catalogs.

Set up the software dependencies:
  salloc -N 1 -C cpu -A desi -t 01:00:00 --qos interactive

  source /dvs_ro/common/software/desi/desi_environment.sh main
  module swap desiutil/3.4.2
  module swap desispec/0.60.2
  module swap desitarget/2.6.1
  module swap desimodel/0.19.0
  module swap speclite/v0.17

srun --ntasks 128 $HOME/code/desihub/desi-photometry/mpi-photometry --outdir $PSCRATCH/lsdr9/fuji --zcatdir $DESI_ROOT_READONLY/spectro/redux/fuji/zcatalog --specprod fuji --targetphot

"""
import os, sys, time, pdb
import numpy as np
import fitsio
from glob import glob
from astropy.table import Table, vstack

from desitarget import geomask
from desiutil.depend import add_dependencies, possible_dependencies
from desimodel.footprint import radec2pix

from desiutil.log import get_logger, DEBUG
log = get_logger()


MINIPHOT_COLUMNS = ['SURVEY', 'PROGRAM', 'TILEID', 'TARGETID', 'RA', 'DEC',
                    'PHOTSYS', 'RELEASE', 'BRICKNAME', 'BRICKID', 'BRICK_OBJID']
ALLSURVEYS = ['cmx', 'sv1', 'sv2', 'sv3', 'special', 'main']
ALLPROGRAMS = ['backup', 'bright', 'dark', 'other']


def get_tractorphot_filename(specprod, nside, healpix, outdir='.', potential=False):
    """Build the filenames for the output tractorphot catalogs.

    """
    if potential:
        prefix = '-potential'
        subdir = 'potential-targets'
    else:
        prefix = ''
        subdir = 'observed-targets'

    tractorphot_outfile = os.path.join(outdir, subdir, 'tractorphot', f'tractorphot{prefix}-' + \
                                       f'nside{nside}-hp{healpix:03d}-{specprod}.fits')
    return tractorphot_outfile


def get_targetphot_filenames(survey, program, specprod, outdir='.',
                             healpix=None, nside=None, potential=False):
    """Buile the filenames for the output targetphot catalogs.

    """
    if potential:
        prefix = '-potential'
        subdir = 'potential-targets'
    else:
        prefix = ''
        subdir = 'observed-targets'

    if healpix is None and nside is None:
        targetphot_outfile = os.path.join(outdir, subdir, f'targetphot{prefix}-{survey}-{program}-{specprod}.fits')
        zcat_outfile = os.path.join(outdir, 'ancillary', f'targetphot{prefix}-zcat-{survey}-{program}-{specprod}.fits')
        miniphot_outfile = os.path.join(outdir, 'ancillary', f'targetphot{prefix}-miniphot-{survey}-{program}-{specprod}.fits')
    else:
        if healpix == '*':
            targetphot_outfile = sorted(glob(os.path.join(outdir, subdir, f'targetphot{prefix}-nside{nside}-' + \
                                                          f'hp*-{survey}-{program}-{specprod}.fits')))
            zcat_outfile = sorted(glob(os.path.join(outdir, 'ancillary', f'targetphot{prefix}-zcat-nside{nside}-' + \
                                                    f'hp*-{survey}-{program}-{specprod}.fits')))
            miniphot_outfile = sorted(glob(os.path.join(outdir, 'ancillary', f'targetphot{prefix}-miniphot-nside{nside}-' + \
                                                        f'hp*-{survey}-{program}-{specprod}.fits')))
        else:
            targetphot_outfile = os.path.join(outdir, subdir, f'targetphot{prefix}-nside{nside}-' + \
                                              f'hp{healpix:02}-{survey}-{program}-{specprod}.fits')
            zcat_outfile = os.path.join(outdir, 'ancillary', f'targetphot{prefix}-zcat-nside{nside}-' + \
                                        f'hp{healpix:02}-{survey}-{program}-{specprod}.fits')
            miniphot_outfile = os.path.join(outdir, 'ancillary', f'targetphot{prefix}-miniphot-nside{nside}-' + \
                                            f'hp{healpix:02}-{survey}-{program}-{specprod}.fits')

    return targetphot_outfile, zcat_outfile, miniphot_outfile


def _read_one_zcat(args):
    """Multiprocessing wrapper."""
    return read_one_zcat(*args)


def read_one_zcat(catfile, rows=None):
    """Read a single redshift catalog, e.g., ztile-sv1-dark-cumulative.fits.

    Args:
        catfile (str): full path to a given redshift catalog

    Returns an astropy.table.Table with the following columns needed to do the
    downstream matching and to enable QA: TARGETID, TILEID, TARGET_RA,
    TARGET_DEC, PETAL_LOC.

    """
    if rows is None:
        from desitarget.targets import decode_targetid
        hdr = fitsio.read_header(catfile, ext='ZCATALOG')
        survey, program = hdr['SURVEY'], hdr['PROGRAM']
        # Remove sky fibers and negative targetids (stuck fibers).
        alltargetids = fitsio.read(catfile, ext='ZCATALOG', columns='TARGETID')
        original_row = np.arange(len(alltargetids))
        _, _, _, _, sky, _ = decode_targetid(alltargetids)
        I = np.where((sky == 0) * (alltargetids > 0))[0]
        if len(I) > 0:
            cat = Table(fitsio.read(catfile, ext='ZCATALOG', rows=I, columns=[
                'TARGETID', 'TILEID', 'TARGET_RA', 'TARGET_DEC', 'PETAL_LOC']))
            original_row = original_row[I]
            # Remove duplicate observations within a given tile; e.g., in survey=sv1,
            # program=other, tileid=80870 there are 8384 observations, but only 4192 of
            # those are unique targetids.
            indx = []
            for tileid in np.unique(cat['TILEID']):
                I = np.where(tileid == cat['TILEID'])[0]
                _, uindx = np.unique(cat['TARGETID'][I], return_index=True)
                indx.append(I[uindx])
            indx = np.hstack(indx)
            cat = cat[indx]
            original_row = original_row[indx]
            cat['SURVEY'] = survey
            cat['PROGRAM'] = program
            cat['ROW'] = original_row
            log.info(f'Read {len(cat):,d}/{len(alltargetids):,d} objects from {catfile}')
    else:
        hdr = fitsio.read_header(catfile, ext='ZCATALOG')
        survey, program = hdr['SURVEY'], hdr['PROGRAM']
        cat = Table(fitsio.read(catfile, ext='ZCATALOG', rows=rows, columns=[
            'TARGETID', 'TILEID', 'TARGET_RA', 'TARGET_DEC', 'PETAL_LOC']))
        cat['SURVEY'] = survey
        cat['PROGRAM'] = program

    return cat


def _read_one_potential_targets(args):
    """Multiprocessing wrapper."""
    return read_one_potential_targets(*args)


def read_one_potential_targets(tileid, survey, program):
    """Read the potential targets in a given fiberassign tile.

    Args:
        tileid (int): tile ID number

    Returns an astropy.table.Table with the following columns needed downstream:
    TARGETID, RA, DEC.

    """
    from desitarget.targets import decode_targetid

    fiberassign_dir = os.path.join(os.getenv('DESI_ROOT_READONLY'), 'target', 'fiberassign', 'tiles', 'trunk')

    stileid = '{:06d}'.format(tileid)
    fiberfile = os.path.join(fiberassign_dir, stileid[:3], f'fiberassign-{stileid}.fits.gz')
    #log.info('Reading {}'.format(fiberfile))

    out = Table(fitsio.read(fiberfile, ext='TARGETS', columns=['TARGETID', 'RA', 'DEC']))

    # remove skies
    _, _, _, _, sky, _ = decode_targetid(out['TARGETID'])
    keep = (sky == 0) * (out['TARGETID'] > 0)
    out = out[keep]

    out['TILEID'] = tileid
    out['SURVEY'] = survey
    out['PROGRAM'] = program

    return out


def _tractorphot_onebrick(args):
    """Multiprocessing wrapper."""
    return tractorphot_onebrick(*args)


def tractorphot_onebrick(cat, RACOLUMN='TARGET_RA', DECCOLUMN='TARGET_DEC'):
    """Simple wrapper on desispec.io.photo.gather_tractorphot."""
    from desispec.io.photo import gather_tractorphot
    tractorphot = gather_tractorphot(cat, racolumn=RACOLUMN, deccolumn=DECCOLUMN)
    return tractorphot


def _targetphot_onetile(args):
    """Multiprocessing wrapper."""
    return targetphot_onetile(*args)


def targetphot_onetile(input_cat, racolumn='TARGET_RA', deccolumn='TARGET_DEC'):
    """Simple wrapper on desispec.io.photo.gather_targetphot."""
    from desispec.io.photo import gather_targetphot
    from desiutil.names import radec_to_desiname

    # should be unique!
    assert(len(input_cat) == len(np.unique(input_cat['TARGETID'])))

    targetphot = gather_targetphot(input_cat, racolumn=racolumn, deccolumn=deccolumn, verbose=False)

    # Can have the same targetid across different surveys and even within a
    # survey, across different tiles. So we need these columns.
    # See https://github.com/moustakas/desi-photometry/issues/3
    targetphot['SURVEY'] = input_cat['SURVEY']
    targetphot['PROGRAM'] = input_cat['PROGRAM']
    targetphot['TILEID'] = input_cat['TILEID']
    targetphot['DESINAME'] = radec_to_desiname(targetphot['RA'], targetphot['DEC'])

    # Replace proper-motion NaNs with zeros.
    inan = np.logical_or(np.isnan(targetphot['PMRA']), np.isnan(targetphot['PMDEC']))
    if np.any(inan):
        targetphot['PMRA'][inan] = 0.0
        targetphot['PMDEC'][inan] = 0.0

    return targetphot


def write_tractorphot(tractorphot, miniphot=None, outfile=None,
                      nside=None, healpix=None, sort=True):
    """Simple wrapper to write out a tractorphot catalog.

    """
    if tractorphot is not None and miniphot is not None:
        if sort:
            srt = geomask.match_to(tractorphot['TARGETID'], miniphot['TARGETID'])
            tractorphot = tractorphot[srt]

        if not np.all(tractorphot['TARGETID'] == miniphot['TARGETID']):
            errmsg = f'Mismatching tractorphot and miniphot catalogs!'
            log.critical(errmsg)
            raise ValueError(errmsg)

    if outfile is not None:
        add_dependencies(tractorphot.meta, envvar_names=['DESI_ROOT', 'DESI_ROOT_READONLY'],
                         module_names=possible_dependencies)

        if nside is not None and healpix is not None:
            tractorphot.meta['FILENSID'] = (nside, 'HEALPix nside number')
            tractorphot.meta['FILENEST'] = (True, 'HEALPix nested (not ring) ordering')
            tractorphot.meta['FILEHPIX'] = (healpix, 'HEALPix number')
        else:
            for popkey in ['FILENSID', 'FILENEST', 'FILEHPIX']:
                if popkey in tractorphot.meta.keys():
                    tractorphot.meta.pop(popkey)

        tractorphot.meta['EXTNAME'] = 'TRACTORPHOT'

    igood = np.where(tractorphot['BRICKNAME'] != '')[0]
    if len(igood) > 0:
        log.info(f'Writing {len(igood):,d} objects to {outfile}')
        tractorphot[igood].write(outfile, overwrite=True)

    inone = np.where(tractorphot_pixel['BRICKNAME'] == '')[0]
    if len(inone) > 0:
        log.info(f'No Tractor photometry found for {len(inone):,d}/{len(igood):,d} objects ' + \
                 f"from {len(set(tractorphot['BRICKNAME'])):,d} unique bricks")


def write_targetphot(targetphot=None, zcat=None, miniphot=None, survey=None,
                     program=None, targetphot_outfile=None, zcat_outfile=None,
                     miniphot_outfile=None, sort=True, nside=None, healpix=None):
    """Simple wrapper to write out a targetphot catalog and its ancillary catalogs.

    """
    # Optionally row-match targetphot_program to zcat_program, taking into account
    # that, e.g., since different ranks can finish at different times and
    # targetids can repeat across tiles, we need to sort on a tileid-targetid
    # key.
    if targetphot is not None and zcat is not None:
        if sort:
            zkey = [f'{tile}-{tid}' for tile, tid in zip(zcat['TILEID'], zcat['TARGETID'])]
            tkey = [f'{tile}-{tid}' for tile, tid in zip(targetphot['TILEID'], targetphot['TARGETID'])]
            zsrt = geomask.match_to(tkey, zkey)
            targetphot = targetphot[zsrt]

        if not np.all(targetphot['TARGETID'] == zcat['TARGETID']):
            errmsg = f'Mismatching targetphot and zcat catalogs!'
            log.critical(errmsg)
            raise ValueError(errmsg)


    if targetphot is not None:
        # remove extraneous targeting bits -
        # https://github.com/moustakas/desi-photometry/issues/13
        if survey == 'main' or survey == 'special':
            remcols = ['CMX_TARGET',
                       'SV1_DESI_TARGET', 'SV1_BGS_TARGET', 'SV1_MWS_TARGET',
                       'SV2_DESI_TARGET', 'SV2_BGS_TARGET', 'SV2_MWS_TARGET',
                       'SV3_DESI_TARGET', 'SV3_BGS_TARGET', 'SV3_MWS_TARGET',
                       'SV1_SCND_TARGET', 'SV2_SCND_TARGET','SV3_SCND_TARGET']
            for remcol in remcols:
                if remcol in targetphot.colnames:
                    targetphot.remove_column(remcol)

        if targetphot_outfile is not None:
            add_dependencies(targetphot.meta, envvar_names=['DESI_ROOT', 'DESI_ROOT_READONLY'],
                             module_names=possible_dependencies)
            if survey is not None:
                targetphot.meta['SURVEY'] = (survey, 'survey name')
            else:
                if 'SURVEY' in targetphot.meta.keys():
                    targetphot.meta.pop('SURVEY')

            if program is not None:
                targetphot.meta['PROGRAM'] = (program, 'program name')
            else:
                if 'PROGRAM' in targetphot.meta.keys():
                    targetphot.meta.pop('PROGRAM')

            if nside is not None and healpix is not None:
                targetphot.meta['FILENSID'] = (nside, 'HEALPix nside number')
                targetphot.meta['FILENEST'] = (True, 'HEALPix nested (not ring) ordering')
                targetphot.meta['FILEHPIX'] = (healpix, 'HEALPix number')
            else:
                for popkey in ['FILENSID', 'FILENEST', 'FILEHPIX']:
                    if popkey in targetphot.meta.keys():
                        targetphot.meta.pop(popkey)

            targetphot.meta['EXTNAME'] = 'TARGETPHOT'

            log.info(f'Writing {len(targetphot):,d} objects to {targetphot_outfile}')
            targetphot.write(targetphot_outfile, overwrite=True)

        if survey is not None and 'SURVEY' not in targetphot.colnames:
            targetphot['SURVEY'] = survey
        if program is not None and 'PROGRAM' not in targetphot.colnames:
            targetphot['PROGRAM'] = program

        # Build a "mini" ancillary catalog that we will use to query the Tractor
        # catalogs, below.
        miniphot = targetphot[MINIPHOT_COLUMNS]

    if miniphot is not None and miniphot_outfile is not None:
        add_dependencies(miniphot.meta, envvar_names=['DESI_ROOT', 'DESI_ROOT_READONLY'],
                         module_names=possible_dependencies)

        if survey is not None:
            miniphot.meta['SURVEY'] = (survey, 'survey name')
        else:
            if 'SURVEY' in miniphot.meta.keys():
                miniphot.meta.pop('SURVEY')

        if program is not None:
            miniphot.meta['PROGRAM'] = (program, 'program name')
        else:
            if 'PROGRAM' in targetphot.meta.keys():
                miniphot.meta.pop('PROGRAM')

        if nside is not None and healpix is not None:
            miniphot.meta['FILENSID'] = (nside, 'HEALPix nside number')
            miniphot.meta['FILENEST'] = (True, 'HEALPix nested (not ring) ordering')
            miniphot.meta['FILEHPIX'] = (healpix, 'HEALPix number')
        else:
            for popkey in ['FILENSID', 'FILENEST', 'FILEHPIX']:
                if popkey in miniphot.meta.keys():
                    miniphot.meta.pop(popkey)

        miniphot.meta['EXTNAME'] = 'MINIPHOT'
        log.info(f'Writing {len(miniphot):,d} objects to {miniphot_outfile}')
        miniphot.write(miniphot_outfile, overwrite=True)


    if zcat is not None and zcat_outfile is not None:
        add_dependencies(zcat.meta, envvar_names=['DESI_ROOT', 'DESI_ROOT_READONLY'],
                         module_names=possible_dependencies)
        if survey is not None:
            zcat.meta['SURVEY'] = (survey, 'survey name')
        else:
            if 'SURVEY' in zcat.meta.keys():
                zcat.meta.pop('SURVEY')

        if program is not None:
            zcat.meta['PROGRAM'] = (program, 'program name')
        else:
            if 'PROGRAM' in zcat.meta.keys():
                zcat.meta.pop('PROGRAM')

        zcat.meta['EXTNAME'] = 'ZCATALOG'
        log.info(f'Writing {len(zcat):,d} objects to {zcat_outfile}')
        zcat.write(zcat_outfile, overwrite=True)


    return targetphot, zcat, miniphot


def targetphot_observed(specprod, zcatdir, outdir, comm=None, mp=1, nside=1,
                        surveys=ALLSURVEYS, programs=ALLPROGRAMS,
                        debug_ntiles=None, overwrite=False):
    """Gather targeting photometry for observed targets.

    """
    if comm is None:
        rank, size = 0, 1
    else:
        rank, size = comm.rank, comm.size

    RACOLUMN, DECCOLUMN = 'TARGET_RA', 'TARGET_DEC'

    ntiles_per_chunk = 10

    if rank == 0:
        tall = time.time()

        if not os.path.isdir(os.path.join(outdir, 'observed-targets')):
            os.makedirs(os.path.join(outdir, 'observed-targets'), exist_ok=True)
        if not os.path.isdir(os.path.join(outdir, 'ancillary')):
            os.makedirs(os.path.join(outdir, 'ancillary'), exist_ok=True)

    # Divide by survey.
    for survey in surveys:
        if rank == 0:
            tsurvey = time.time()

        #  Divide by program.
        for program in programs:
            if rank == 0:
                tprogram = time.time()

            zcatfile = os.path.join(zcatdir, f'ztile-{survey}-{program}-cumulative.fits')
            if not os.path.isfile(zcatfile):
                if rank == 0:
                    log.warning(f'No redshift catalog {zcatfile} found for {survey}:{program}')
                continue

            # Are we already done? All surveys/programs except
            # main/{bright,dark} have merged catalogs.
            if survey == 'main' and (program == 'bright' or program == 'dark'):
                pass
            else:
                targetphot_outfile, _, _ = get_targetphot_filenames(
                    survey, program, specprod, outdir=outdir)
                if os.path.isfile(targetphot_outfile) and not overwrite:
                    if rank == 0:
                        log.info(f'Skipping existing targetphot file {targetphot_outfile}')
                    continue

            # Initialize the variables we will be broadcasting.
            if comm is not None and size > 1:
                upixels = None
                zcat_rows_bypixel = None

            # Read the appropriate redshift catalog on rank 0.
            if rank == 0:
                log.info(f'Working on {survey}:{program}')

                zcat_program = read_one_zcat(zcatfile)

                # Optionally test with a smaller number of tiles.
                if debug_ntiles is not None:
                    print('Debugging with a smaller sample...')
                    utiles = np.unique(zcat_program['TILEID'])
                    if len(utiles) > 1:
                        I = np.random.choice(len(utiles), debug_ntiles, replace=False)
                        zcat_program = zcat_program[np.isin(zcat_program['TILEID'], utiles[I])]

                allpixels = radec2pix(nside, zcat_program['TARGET_RA'], zcat_program['TARGET_DEC'])
                upixels = sorted(set(allpixels))

                # Loop on healpix
                zcat_rows_bypixel = {}
                for pixel in upixels:
                    targetphot_outfile, zcat_outfile, miniphot_outfile = get_targetphot_filenames(
                        survey, program, specprod, outdir=outdir, healpix=pixel, nside=nside)
                    if os.path.isfile(targetphot_outfile) and not overwrite:
                        log.warning(f'Skipping existing targetphot file {targetphot_outfile}')
                        continue

                    P = np.where(pixel == allpixels)[0]
                    zcat_pixel = zcat_program[P]
                    utiles_onepixel = np.unique(zcat_pixel['TILEID'].value)

                    # If using MPI-parallelization, set up the arrays we need...
                    if comm is not None and size > 1:
                        # Divide tiles ~equally among the available ranks.
                        log.info(f'Pixel {pixel:03d}: distributing {len(zcat_pixel):,d} TARGETIDs and ' + \
                                 f'{len(utiles_onepixel):,d} unique tiles from {survey}:{program} to {size-1} ranks.')

                        utiles_byrank = np.array_split(utiles_onepixel, size-1)

                        # For each rank, loop over chunks of tiles and store
                        # the rows to the full redshift catalog.
                        zcat_rows_byrank = []
                        for onerank in range(size-1):
                            log.debug(f'Rank 0: building index list for rank {onerank+1}')
                            # So we don't hit the disk as often, process
                            # ntiles_per_chunk at a time.
                            utiles = utiles_byrank[onerank]
                            zcat_rows_manytiles = []
                            if len(utiles) > 0: # no work
                                nchunk = int(np.ceil(len(utiles) / ntiles_per_chunk))
                                for ichunk in range(nchunk):
                                    i1 = ichunk*ntiles_per_chunk
                                    i2 = (ichunk+1)*ntiles_per_chunk
                                    I = np.where(np.isin(zcat_pixel['TILEID'], utiles[i1:i2]))[0]
                                    zcat_rows_manytiles.append(zcat_pixel[I]['ROW'].value)
                            zcat_rows_byrank.append(zcat_rows_manytiles)
                        zcat_rows_bypixel[pixel] = zcat_rows_byrank
                    else:
                        # ...otherwise just loop on the unique set of tiles and write out.
                        log.info(f'Pixel {pixel:03d}: working on {len(zcat_pixel):,d} TARGETIDs and ' + \
                                 f'{len(utiles_onepixel):,d} unique tiles from {survey}:{program}.')
                        targetphot_pixel = []
                        for tileid in utiles_onepixel:
                            I = np.where(tileid == zcat_pixel['TILEID'].value)[0]
                            _targetphot_onetile = targetphot_onetile(zcat_pixel[I], RACOLUMN, DECCOLUMN)
                            targetphot_pixel.append(_targetphot_onetile)

                        if len(targetphot_pixel) == 0:
                            errmsg = 'No targeting catalogs were generated for survey/program/pixel ' + \
                                f'{survey}:{program}:{pixel:02}'
                            log.critical(errmsg)
                            raise ValueError(errmsg)

                        targetphot_pixel = vstack(targetphot_pixel)
                        targetphot_pixel, zcat_pixel, miniphot_pixel = write_targetphot(
                            targetphot_pixel, zcat=zcat_pixel, targetphot_outfile=targetphot_outfile,
                            zcat_outfile=zcat_outfile, miniphot_outfile=miniphot_outfile,
                            survey=survey, program=program, healpix=pixel, nside=nside, sort=True)


            # If parralelizing, broadcast the per-pixel list of zcat rows
            # assigned to each rank and then loop.
            if comm is not None and size > 1:
                upixels = comm.bcast(upixels, root=0)
                zcat_rows_bypixel = comm.bcast(zcat_rows_bypixel, root=0)

                for pixel in upixels:
                    targetphot_pixel = []
                    if comm is not None and size > 1:
                        # Ranks >0 loop over their list of tiles, generate the per-tile
                        # targetphot catalogs, and then send the stacked results back
                        # to rank 0...
                        if rank > 0:
                            if not pixel in zcat_rows_bypixel.keys(): # pixel is already done
                                comm.send(Table(), dest=0)
                            else:
                                zcat_rows_manytiles = zcat_rows_bypixel[pixel][rank-1]
                                nchunk = len(zcat_rows_manytiles)
                                if nchunk == 0: # not all ranks have work
                                    comm.send(Table(), dest=0)
                                else:
                                    targetphot_onerank = []
                                    for ichunk in range(nchunk):
                                        zcat_rows = zcat_rows_manytiles[ichunk]
                                        log.info(f'Rank {rank}: reading {len(zcat_rows):,d} targets from {zcatfile}')
                                        zcat_manytiles = read_one_zcat(zcatfile, rows=zcat_rows)
                                        # now loop through unique tiles
                                        alltiles = zcat_manytiles['TILEID'].value
                                        for tileid in np.unique(alltiles):
                                            I = np.where(tileid == alltiles)[0]
                                            _targetphot_onetile = targetphot_onetile(zcat_manytiles[I], RACOLUMN, DECCOLUMN)
                                            targetphot_onerank.append(_targetphot_onetile)
                                    del zcat_manytiles, _targetphot_onetile
                                    targetphot_onerank = vstack(targetphot_onerank)
                                    log.info(f'Pixel {pixel:03}: rank {rank}: sending targeting photometry for ' + \
                                             f'{len(targetphot_onerank):,d} targets back to rank 0')
                                    comm.send(targetphot_onerank, dest=0)
                        else:
                            # ...while rank 0 receives them.
                            for onerank in range(1, size):
                                targetphot_onerank = comm.recv(source=onerank)
                                log.info('Rank 0: received targeting photometry for ' + \
                                         f'{len(targetphot_onerank):,d} targets from rank {onerank}')
                                targetphot_pixel.append(targetphot_onerank)
                            del targetphot_onerank

                    if comm is not None and size > 1:
                        comm.barrier()

                    # sort and write out on rank 0
                    if rank == 0:
                        # This is only empty if all the catalogs already exist,
                        # which is fine.
                        if len(targetphot_pixel) >= 0:
                            targetphot_pixel = vstack(targetphot_pixel)

                            P = np.where(pixel == allpixels)[0]
                            zcat_pixel = zcat_program[P]

                            targetphot_outfile, zcat_outfile, miniphot_outfile = get_targetphot_filenames(
                                survey, program, specprod, outdir=outdir, healpix=pixel, nside=nside)

                            targetphot_pixel, zcat_pixel, mini_pixel = write_targetphot(
                                targetphot_pixel, zcat=zcat_pixel, targetphot_outfile=targetphot_outfile,
                                zcat_outfile=zcat_outfile, miniphot_outfile=miniphot_outfile,
                                survey=survey, program=program, healpix=pixel, nside=nside, sort=True)


            if rank == 0:
                # For all surveys except 'main'/{bright,dark}, gather up the
                # individual healpix files and merge them. Always gather up the
                # 'zcat' and 'miniphot' files.
                targetphot_files, zcat_files, miniphot_files = get_targetphot_filenames(
                    survey, program, specprod, outdir=outdir, healpix='*', nside=nside)
                targetphot_outfile, zcat_outfile, miniphot_outfile = get_targetphot_filenames(
                    survey, program, specprod, outdir=outdir)

                if survey == 'main' and (program == 'bright' or program == 'dark'):
                    zcat_program = []
                    miniphot_program = []
                    for zcat_file, miniphot_file in zip(zcat_files, miniphot_files):
                        zcat_program.append(Table(fitsio.read(zcat_file)))
                        miniphot_program.append(Table(fitsio.read(miniphot_file)))
                        os.remove(zcat_file)
                        os.remove(miniphot_file)
                    zcat_program = vstack(zcat_program)
                    miniphot_program = vstack(miniphot_program)

                    write_targetphot(zcat=zcat_program, miniphot=miniphot_program,
                                     zcat_outfile=zcat_outfile,
                                     miniphot_outfile=miniphot_outfile,
                                     survey=survey, program=program)
                else:
                    zcat_program = []
                    miniphot_program = []
                    targetphot_program = []
                    for targetphot_file, zcat_file, miniphot_file in zip(targetphot_files, zcat_files, miniphot_files):
                        zcat_program.append(Table(fitsio.read(zcat_file)))
                        miniphot_program.append(Table(fitsio.read(miniphot_file)))
                        targetphot_program.append(Table(fitsio.read(targetphot_file)))
                        os.remove(zcat_file)
                        os.remove(miniphot_file)
                        os.remove(targetphot_file)
                    zcat_program = vstack(zcat_program)
                    miniphot_program = vstack(miniphot_program)
                    targetphot_program = vstack(targetphot_program)

                    write_targetphot(targetphot_program, zcat=zcat_program,
                                     miniphot=miniphot_program,
                                     targetphot_outfile=targetphot_outfile,
                                     zcat_outfile=zcat_outfile,
                                     miniphot_outfile=miniphot_outfile,
                                     survey=survey, program=program, sort=True)

                log.info(f'Total time for {survey}:{program}: {(time.time()-tprogram)/60.:.3f} min')

        if rank == 0:
            log.info(f'Total time for {survey} (all programs): {(time.time()-tsurvey)/60.:.3f} min')

    if rank == 0:
        log.info(f'Total time for all surveys: {(time.time()-tall)/60.:.3f} min')


def targetphot_potential(specprod, outdir, comm=None, mp=1, nside=2,
                         surveys=ALLSURVEYS, programs=ALLPROGRAMS,
                         debug_ntiles=None, overwrite=False):
    """Gather targeting photometry for potential targets.

    """
    if comm is None:
        rank, size = 0, 1
    else:
        rank, size = comm.rank, comm.size

    RACOLUMN, DECCOLUMN = 'RA', 'DEC'

    if rank == 0:
        tall = time.time()

        if not os.path.isdir(os.path.join(outdir, 'potential-targets')):
            os.makedirs(os.path.join(outdir, 'potential-targets'), exist_ok=True)

    # Divide by survey.
    for survey in surveys:
        if rank == 0:
            tsurvey = time.time()

        #  Divide by program.
        for program in programs:
            if rank == 0:
                tprogram = time.time()

            # Are we already done? All surveys/programs except
            # main/{bright,dark} have merged catalogs.
            targetphot_outfile, _, _ = get_targetphot_filenames(
                survey, program, specprod, outdir=outdir, potential=True)
            if survey == 'main' and (program == 'bright' or program == 'dark'):
                pass
            else:
                if os.path.isfile(targetphot_outfile) and not overwrite:
                    if rank == 0:
                        log.info(f'Skipping existing targetphot file {targetphot_outfile}')
                    continue

            _, zcatfile, _ = get_targetphot_filenames(survey, program, specprod, outdir=outdir, potential=False)
            if not os.path.isfile(zcatfile):
                if rank == 0:
                    log.warning(f'No redshift catalog {zcatfile} found for {survey}:{program}')
                continue

            # Initialize the variables we will be broadcasting.
            if comm is not None and size > 1:
                upixels = None
                utiles_bypixel = None

            # Read the appropriate redshift catalog on rank 0.
            if rank == 0:
                log.info(f'Working on {survey}:{program}')

                zcat_program = Table(fitsio.read(zcatfile))

                # Optionally test with a smaller number of tiles.
                if debug_ntiles is not None:
                    print('Debugging with a smaller sample...')
                    utiles = np.unique(zcat_program['TILEID'])
                    if len(utiles) > 1:
                        I = np.random.choice(len(utiles), debug_ntiles, replace=False)
                        zcat_program = zcat_program[np.isin(zcat_program['TILEID'], utiles[I])]

                allpixels = radec2pix(nside, zcat_program['TARGET_RA'], zcat_program['TARGET_DEC'])
                upixels = sorted(set(allpixels))

                # Loop on healpix
                utiles_bypixel = {}
                for pixel in upixels:
                    targetphot_outfile, _, miniphot_outfile = get_targetphot_filenames(
                        survey, program, specprod, outdir=outdir, healpix=pixel,
                        nside=nside, potential=True)
                    if os.path.isfile(targetphot_outfile) and not overwrite:
                        log.warning(f'Skipping existing targetphot file {targetphot_outfile}')
                        continue

                    P = np.where(pixel == allpixels)[0]
                    zcat_pixel = zcat_program[P]
                    utiles_onepixel = np.unique(zcat_pixel['TILEID'].value)

                    # If using MPI-parallelization, set up the arrays we need...
                    if comm is not None and size > 1:
                        # Divide tiles ~equally among the available ranks.
                        log.info(f'Pixel {pixel:03}: distributing {len(utiles_onepixel):,d} unique ' + \
                                 f'tiles from {survey}:{program} to {size-1} ranks.')

                        utiles_byrank = np.array_split(utiles_onepixel, size-1)
                        utiles_bypixel[pixel] = utiles_byrank
                    else:
                        # ...otherwise just loop on the unique set of tiles and write out.
                        log.info(f'Pixel {pixel:03}: working on {len(zcat_pixel):,d} TARGETIDs and ' + \
                                 f'{len(utiles_onepixel):,d} unique tiles from {survey}:{program}.')
                        targetphot_pixel = []
                        for tileid in utiles_onepixel:
                            potential_targets = read_one_potential_targets(tileid, survey, program)
                            _targetphot_onetile = targetphot_onetile(potential_targets, RACOLUMN, DECCOLUMN)
                            targetphot_pixel.append(_targetphot_onetile)

                        if len(targetphot_pixel) == 0:
                            errmsg = 'No potential targeting catalogs were generated for survey/program/pixel ' + \
                                f'{survey}:{program}:{pixel:03}'
                            log.critical(errmsg)
                            raise ValueError(errmsg)

                        targetphot_pixel = vstack(targetphot_pixel)
                        targetphot_pixel, _, miniphot_pixel = write_targetphot(
                            targetphot_pixel, targetphot_outfile=targetphot_outfile,
                            miniphot_outfile=miniphot_outfile, survey=survey, program=program,
                            healpix=pixel, nside=nside)

            # If parralelizing, broadcast the per-pixel list of zcat rows
            # assigned to each rank and then loop.
            if comm is not None and size > 1:
                upixels = comm.bcast(upixels, root=0)
                utiles_bypixel = comm.bcast(utiles_bypixel, root=0)

                for pixel in upixels:
                    targetphot_pixel = []
                    if comm is not None and size > 1:
                        # Ranks >0 loop over their list of tiles, generate the
                        # per-tile targetphot-potential catalogs, and then send
                        # the stacked results back to rank 0...
                        if rank > 0:
                            utiles_onepixel = utiles_bypixel[pixel][rank-1]
                            if len(utiles_onepixel) == 0: # not all ranks have work
                                comm.send(Table(), dest=0)
                            else:
                                targetphot_onerank = []
                                for tileid in utiles_onepixel:
                                    potential_targets = read_one_potential_targets(tileid, survey, program)
                                    _targetphot_onetile = targetphot_onetile(potential_targets, RACOLUMN, DECCOLUMN)
                                    targetphot_onerank.append(_targetphot_onetile)

                                if len(targetphot_onerank) == 0:
                                    errmsg = f'Rank {rank}: no potential targeting catalogs were generated for ' + \
                                        f'survey/program/pixel {survey}:{program}:{pixel:03}'
                                    log.critical(errmsg)
                                    raise ValueError(errmsg)

                                targetphot_onerank = vstack(targetphot_onerank)
                                log.info(f'Pixel {pixel:03}: rank {rank}: sending targeting photometry for ' + \
                                         f'{len(targetphot_onerank):,d} targets back to rank 0')
                                comm.send(targetphot_onerank, dest=0)
                        else:
                            # ...while rank 0 receives them.
                            for onerank in range(1, size):
                                targetphot_onerank = comm.recv(source=onerank)
                                log.info('Rank 0: received targeting photometry for ' + \
                                         f'{len(targetphot_onerank):,d} targets from rank {onerank}')
                                targetphot_pixel.append(targetphot_onerank)
                            del targetphot_onerank

                    if comm is not None and size > 1:
                        comm.barrier()

                    # sort and write out on rank 0
                    if rank == 0:
                        if len(targetphot_pixel) == 0:
                            errmsg = 'No targeting catalogs were generated for survey/program/pixel ' + \
                                f'{survey}:{program}:{pixel:03}'
                            log.critical(errmsg)
                            raise ValueError(errmsg)
                        targetphot_pixel = vstack(targetphot_pixel)

                        targetphot_outfile, _, miniphot_outfile = get_targetphot_filenames(
                            survey, program, specprod, outdir=outdir, healpix=pixel, nside=nside,
                            potential=True)

                        targetphot_pixel, _, miniphot_pixel = write_targetphot(
                            targetphot_pixel, targetphot_outfile=targetphot_outfile,
                            miniphot_outfile=miniphot_outfile, survey=survey, program=program,
                            healpix=pixel, nside=nside)


            if rank == 0:
                # For all surveys except 'main'/{bright,dark}, gather up the
                # individual healpix files and merge them. Always gather up the
                # 'miniphot' files.
                targetphot_files, _, miniphot_files = get_targetphot_filenames(
                    survey, program, specprod, outdir=outdir, healpix='*', nside=nside, potential=True)
                targetphot_outfile, _, miniphot_outfile = get_targetphot_filenames(
                    survey, program, specprod, outdir=outdir, potential=True)

                if survey == 'main' and (program == 'bright' or program == 'dark'):
                    miniphot_program = []
                    for miniphot_file in miniphot_files:
                        miniphot_program.append(Table(fitsio.read(miniphot_file)))
                        os.remove(miniphot_file)
                    miniphot_program = vstack(miniphot_program)

                    write_targetphot(miniphot=miniphot_program, miniphot_outfile=miniphot_outfile,
                                     survey=survey, program=program)
                else:
                    miniphot_program = []
                    targetphot_program = []
                    for targetphot_file, miniphot_file in zip(targetphot_files, miniphot_files):
                        miniphot_program.append(Table(fitsio.read(miniphot_file)))
                        targetphot_program.append(Table(fitsio.read(targetphot_file)))
                        os.remove(miniphot_file)
                        os.remove(targetphot_file)
                    targetphot_program = vstack(targetphot_program)
                    miniphot_program = vstack(miniphot_program)

                    write_targetphot(targetphot_program, miniphot=miniphot_program,
                                     targetphot_outfile=targetphot_outfile,
                                     miniphot_outfile=miniphot_outfile, survey=survey,
                                     program=program, sort=True)

                log.info(f'Total time for {survey}:{program}: {(time.time()-tprogram)/60.:.3f} min')

        if rank == 0:
            log.info(f'Total time for {survey} (all programs): {(time.time()-tsurvey)/60.:.3f} min')

    if rank == 0:
        log.info(f'Total time for all surveys: {(time.time()-tall)/60.:.3f} min')


def tractorphot(specprod, outdir, comm=None, mp=1, nside=4, potential=False,
                surveys=ALLSURVEYS, programs=ALLPROGRAMS, overwrite=False):
    """Gather targeting photometry for observed targets.

    """
    from desitarget.targets import decode_targetid
    from desiutil.brick import brickname as get_brickname
    from desispec.parallel import weighted_partition

    if comm is None:
        rank, size = 0, 1
    else:
        rank, size = comm.rank, comm.size

    RACOLUMN, DECCOLUMN = 'RA', 'DEC'
    if potential:
        #RACOLUMN, DECCOLUMN = 'RA', 'DEC'
        targets_subdir = 'potential-targets'
        suffix = '-potential'
    else:
        #RACOLUMN, DECCOLUMN = 'TARGET_RA', 'TARGET_DEC'
        targets_subdir = 'observed-targets'
        suffix = ''

    nbricks_per_chunk = 50

    # Initialize the variables we will be broadcasting.
    if comm is not None and size > 1:
        upixels = None
        miniphot_rows_bypixel = None

    if rank == 0:
        tall = time.time()

        if not os.path.isdir(os.path.join(outdir, targets_subdir, 'tractorphot')):
            os.makedirs(os.path.join(outdir, targets_subdir, 'tractorphot'), exist_ok=True)

        # Gather up the miniphot catalogs across all surveys and programs.
        miniphot = []
        for survey in surveys:
            for program in programs:
                _, _, miniphot_file = get_targetphot_filenames(survey, program, specprod, outdir=outdir, potential=potential)
                if os.path.isfile(miniphot_file): # not all survey-program combinations exist
                    mini = Table(fitsio.read(miniphot_file))
                    log.info(f'Read {len(mini):,d} objects from {miniphot_file}')
                    miniphot.append(mini)
        miniphot = vstack(miniphot)
        nobj = len(miniphot)

        # TARGETIDs can repeat in and between surveys, so select just unique
        # targets here; that's fine.
        _, uindx = np.unique(miniphot['TARGETID'], return_index=True)
        miniphot = miniphot[uindx]
        log.info(f'Gathering Tractor photometry for {len(miniphot):,d}/{nobj:,d} unique targets')

        # write out a temp file
        miniphotfile = os.path.join(outdir, 'ancillary', f'tmp-targetphot{suffix}-miniphot-{specprod}.fits')
        log.info(f'Writing temporary miniphot catalog {miniphotfile}')
        miniphot.write(miniphotfile, overwrite=True)

        # Some secondary programs (e.g., 39632961435338613, 39632966921487347)
        # have BRICKNAME!='' & BRICKID!=0, but BRICK_OBJID==0. Unpack those here
        # using decode_targetid.
        fix = np.where((miniphot['BRICKNAME'] != '') * (miniphot['BRICK_OBJID'] == 0))[0]
        if len(fix) > 0:
            log.info(f'Inferring BRICK_OBJID for {len(fix):,d} objects using decode_targetid')
            fix_objid, fix_brickid, _, _, _, _ = decode_targetid(miniphot['TARGETID'][fix])
            assert(np.all(fix_brickid == miniphot['BRICKID'][fix]))
            miniphot['BRICK_OBJID'][fix] = fix_objid

        inobrickname = np.where(miniphot['BRICKNAME'] == '')[0]
        if len(inobrickname) > 0:
            log.info(f'Inferring brickname for {len(inobrickname):,d}/{len(miniphot):,d} objects')
            miniphot['BRICKNAME'][inobrickname] = get_brickname(miniphot[RACOLUMN][inobrickname],
                                                                miniphot[DECCOLUMN][inobrickname])
        assert(np.all(miniphot['BRICKNAME'] != ''))

        # Divide the sample into nside healpixels.
        allpixels = radec2pix(nside, miniphot[RACOLUMN].value, miniphot[DECCOLUMN].value)
        upixels = sorted(set(allpixels))

        miniphot_rows_bypixel = {}
        for pixel in upixels:
            tractorphot_outfile = get_tractorphot_filename(
                specprod, nside, pixel, outdir=outdir, potential=potential)
            if os.path.isfile(tractorphot_outfile) and not overwrite:
                log.warning(f'Skipping existing tractorphot file {tractorphot_outfile}')
                continue

            P = np.where(pixel == allpixels)[0]
            miniphot_pixel = miniphot[P]
            ubricks_onepixel, nperbrick = np.unique(miniphot_pixel['BRICKNAME'].value, return_counts=True)

            # If using MPI-parallelization, set up the arrays we need...
            if comm is not None and size > 1:
                # Distribute a weighted distribution of bricks among the available ranks.
                log.info(f'Pixel {pixel:03}: distributing {len(miniphot_pixel):,d} TARGETIDs and ' + \
                         f'{len(ubricks_onepixel):,d} unique bricks to {size-1} ranks.')

                #ubricks_byrank = np.array_split(ubricks_onepixel, size-1)
                groups = weighted_partition(nperbrick, size-1)
                ubricks_byrank = [ubricks_onepixel[group] for group in groups]

                # For each rank, loop over bricks and store the rows to the
                # full 'miniphot' catalog.
                miniphot_rows_byrank = []
                for onerank in range(size-1):
                    log.debug(f'Rank 0: building index list for rank {onerank+1}')
                    # So we don't hit the disk as often, process
                    # ntiles_per_chunk at a time.
                    ubricks = ubricks_byrank[onerank]
                    miniphot_rows_manybricks = []
                    if len(ubricks) > 0: # no work
                        nchunk = int(np.ceil(len(ubricks) / nbricks_per_chunk))
                        for ichunk in range(nchunk):
                            i1 = ichunk*nbricks_per_chunk
                            i2 = (ichunk+1)*nbricks_per_chunk
                            I = np.where(np.isin(miniphot_pixel['BRICKNAME'], ubricks[i1:i2]))[0]
                            miniphot_rows_manybricks.append(miniphot_pixel[I]['ROW'].value)
                    miniphot_rows_byrank.append(miniphot_rows_manybricks)
                miniphot_rows_bypixel[pixel] = miniphot_rows_byrank
            else:
                # ...otherwise just loop on the unique set of bricks and write out.
                log.info(f'Pixel {pixel:03}: working on {len(miniphot_pixel):,d} TARGETIDs and ' + \
                         f'{len(ubricks_onepixel):,d} unique bricks.')
                tractorphot_pixel = []
                for brick in ubricks_onepixel:
                    I = np.where(brick == miniphot_pixel['BRICKNAME'].value)[0]
                    _tractorphot_onebrick = tractorphot_onebrick(miniphot_pixel[I], RACOLUMN, DECCOLUMN)
                    tractorphot_pixel.append(_tractorphot_onebrick)

                if len(tractorphot_pixel) == 0:
                    errmsg = f'No Tractor catalogs were generated for pixel {pixel:03}'
                    log.critical(errmsg)
                    raise ValueError(errmsg)

                tractorphot_pixel = vstack(tractorphot_pixel)
                write_tractorphot(tractorphot_pixel, miniphot=miniphot_pixel, healpix=pixel,
                                  nside=nside, outfile=tractorphot_outfile)

    # If parralelizing, broadcast the per-pixel list of miniphot rows
    # assigned to each rank and then loop.
    if comm is not None and size > 1:
        upixels = comm.bcast(upixels, root=0)
        miniphot_rows_bypixel = comm.bcast(miniphot_rows_bypixel, root=0)

        for pixel in upixels:
            tractorphot_pixel = []
            if comm is not None and size > 1:
                # Ranks >0 loop over their list of bricks, generate the per-brick
                # tractorphot catalogs, and then send the stacked results back
                # to rank 0...
                if rank > 0:
                    if not pixel in miniphot_rows_bypixel.keys(): # pixel is already done
                        comm.send(Table(), dest=0)
                    else:
                        miniphot_rows_manybricks = miniphot_rows_bypixel[pixel][rank-1]
                        nchunk = len(miniphot_rows_manybricks)
                        if nchunk == 0: # not all ranks have work
                            comm.send(Table(), dest=0)
                        else:
                            tractorphot_onerank = []
                            for ichunk in range(nchunk):
                                miniphot_rows = miniphot_rows_manybricks[ichunk]
                                log.info(f'Rank {rank}: reading {len(miniphot_rows):,d} targets from {miniphotfile}')
                                miniphot_manybricks = Table(fitsio.read(miniphotfile, rows=miniphot_rows))
                                # now loop through unique bricks
                                allbricks = miniphot_manybricks['BRICKNAME'].value
                                for brick in np.unique(allbricks):
                                    I = np.where(brick == allbricks)[0]
                                    _tractorphot_onebrick = tractorphot_onebrick(miniphot_manybricks[I], RACOLUMN, DECCOLUMN)
                                    tractorphot_onerank.append(_tractorphot_onebrick)
                            del miniphot_manybricks, _tractorphot_onebrick
                            tractorphot_onerank = vstack(tractorphot_onerank)
                            log.info(f'Pixel {pixel:03}: rank {rank}: sending Tractor photometry for ' + \
                                     f'{len(tractorphot_onerank):,d} targets back to rank 0')
                            comm.send(tractorphot_onerank, dest=0)
                else:
                    # ...while rank 0 receives them.
                    for onerank in range(1, size):
                        tractorphot_onerank = comm.recv(source=onerank)
                        log.info('Rank 0: received Tractor photometry for ' + \
                                 f'{len(tractorphot_onerank):,d} targets from rank {onerank}')
                        tractorphot_pixel.append(tractorphot_onerank)
                    del tractorphot_onerank

            if comm is not None and size > 1:
                comm.barrier()

            # sort and write out on rank 0
            if rank == 0:
                # This is only empty if all the catalogs already exist,
                # which is fine.
                if len(tractorphot_pixel) >= 0:
                    tractorphot_pixel = vstack(tractorphot_pixel)

                    P = np.where(pixel == allpixels)[0]
                    miniphot_pixel = miniphot[P]

                    tractorphot_outfile = get_tractorphot_filename(
                        specprod, nside, pixel, outdir=outdir, potential=potential)

                    write_tractorphot(tractorphot_pixel, miniphot=miniphot_pixel,
                                      outfile=tractorphot_outfile, nside=nside,
                                      healpix=pixel, sort=True)


    pdb.set_trace()



def main():
    """Main wrapper.

    """
    import argparse

    parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    parser.add_argument('--specprod', type=str, required=True, help='Spectroscopic production; output file prefix.')
    parser.add_argument('--zcatdir', type=str, required=True, help='Redshift catalog base directory.')
    parser.add_argument('--surveys', type=str, default=','.join(ALLSURVEYS), help='Comma-separated list of surveys to process.')
    parser.add_argument('--programs', type=str, default=','.join(ALLPROGRAMS), help='Comma-separated list of programs to process.')
    parser.add_argument('--outdir', default='$PSCRATCH/lsdr9', type=str, help='Base output data directory.')

    parser.add_argument('--targetphot', action='store_true', help='Build the observed targets targeting catalogs.')
    parser.add_argument('--tractorphot', action='store_true', help='Build the observed targets tractor catalogs.')
    parser.add_argument('--targetphot-potential', action='store_true', help='Build the potential targets targeting catalogs.')
    parser.add_argument('--tractorphot-potential', action='store_true', help='Build the potential targets tractor catalogs.')

    parser.add_argument('--validate-targetphot', action='store_true', help='Validate the targetphot catalogs.')
    parser.add_argument('--validate-tractorphot', action='store_true', help='Validate the photo-tractor catalogs.')

    parser.add_argument('--mp', type=int, default=1, help='Number of multiprocessing processes per MPI rank or node.')
    parser.add_argument('--debug-ntiles', type=int, default=None, help='Debug with a smaller number of (test) tiles, e.g., --debug-ntiles=10.')
    parser.add_argument('--nside-tractorphot', type=int, default=4, help='healpix nside for tractorphot catalogs.')
    parser.add_argument('--nside-targetphot-observed', type=int, default=1, help='healpix nside for targetphot-observed catalogs.')
    parser.add_argument('--nside-targetphot-potential', type=int, default=2, help='healpix nside for targetphot-potential catalogs.')

    parser.add_argument('--nompi', action='store_true', help='Do not use MPI parallelism.')
    parser.add_argument('--overwrite', action='store_true', help='Overwrite existing files; use with care.')

    args = parser.parse_args()
    log = get_logger()

    args.outdir = os.path.expandvars(args.outdir)
    if not os.path.isdir(args.outdir):
        os.makedirs(args.outdir, exist_ok=True)

    if args.nompi:
        comm = None
    else:
        try:
            from mpi4py import MPI
            comm = MPI.COMM_WORLD
        except ImportError:
            comm = None

    # https://docs.nersc.gov/development/languages/python/parallel-python/#use-the-spawn-start-method
    if args.mp > 1 and 'NERSC_HOST' in os.environ:
        import multiprocessing
        multiprocessing.set_start_method('spawn')

    args.surveys = np.atleast_1d(args.surveys.split(','))
    args.programs = np.atleast_1d(args.programs.split(','))

    if args.targetphot:
        targetphot_observed(args.specprod, args.zcatdir, args.outdir, comm=comm,
                            nside=args.nside_targetphot_observed, mp=args.mp,
                            surveys=args.surveys, programs=args.programs,
                            debug_ntiles=args.debug_ntiles, overwrite=args.overwrite)

    if args.targetphot_potential:
        targetphot_potential(args.specprod, args.outdir, comm=comm, mp=args.mp,
                             nside=args.nside_targetphot_potential,
                             surveys=args.surveys, programs=args.programs,
                             debug_ntiles=args.debug_ntiles,
                             overwrite=args.overwrite)

    if args.tractorphot:
        tractorphot(args.specprod, args.outdir, comm=comm, potential=False,
                    surveys=args.surveys, programs=args.programs,
                    nside=args.nside_tractorphot, overwrite=args.overwrite)

    if args.tractorphot_potential:
        tractorphot(args.specprod, args.outdir, comm=comm, potential=True,
                    surveys=args.surveys, programs=args.programs,
                    nside=args.nside_tractorphot, overwrite=args.overwrite)

if __name__ == '__main__':
    main()
