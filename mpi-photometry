#!/usr/bin/env python3

"""Match data release redshift catalogs against the original photometric
(target) catalogs.

Set up the software dependencies:
  salloc -N 1 -C cpu -A desi -t 01:00:00 --qos interactive

  source /dvs_ro/common/software/desi/desi_environment.sh main
  module swap desiutil/3.4.3
  module swap desispec/0.66.3
  module swap desitarget/2.8.0
  module swap desimodel/0.19.1

srun --ntasks 128 $HOME/code/desihub/desi-photometry/mpi-photometry --outdir $PSCRATCH/lsdr9/kibo --zcatdir $DESI_ROOT_READONLY/spectro/redux/kibo/zcatalog/v1 --specprod kibo --targetphot

"""
import os, time
import numpy as np
import fitsio
from glob import glob
from astropy.table import Table, vstack

from desitarget import geomask
from desiutil.depend import add_dependencies, possible_dependencies
from desimodel.footprint import radec2pix

from desiutil.log import get_logger, DEBUG
log = get_logger()


MINIPHOT_COLUMNS = ['SURVEY', 'PROGRAM', 'TILEID', 'TARGETID', 'RA', 'DEC',
                    'PHOTSYS', 'RELEASE', 'BRICKNAME', 'BRICKID', 'BRICK_OBJID']
ALLSURVEYS = ['cmx', 'sv1', 'sv2', 'sv3', 'special', 'main']
ALLPROGRAMS = ['backup', 'bright', 'dark', 'other']


def get_tractorphot_filename(specprod, nside, healpix, outdir='.', potential=False):
    """Build the filenames for the output tractorphot catalogs.

    """
    if potential:
        prefix = '-potential'
        subdir = 'potential-targets'
    else:
        prefix = ''
        subdir = 'observed-targets'

    tractorphot_outfile = os.path.join(outdir, subdir, 'tractorphot', f'tractorphot{prefix}-' + \
                                       f'nside{nside}-hp{healpix:03}-{specprod}.fits')

    return tractorphot_outfile


def get_targetphot_filenames(survey, program, specprod, outdir='.',
                             healpix=None, nside=None, potential=False):
    """Buile the filenames for the output targetphot catalogs.

    """
    if potential:
        prefix = '-potential'
        subdir = 'potential-targets'
    else:
        prefix = ''
        subdir = 'observed-targets'

    if healpix is None and nside is None:
        targetphot_outfile = os.path.join(outdir, subdir, f'targetphot{prefix}-{survey}-{program}-{specprod}.fits')
        zcat_outfile = os.path.join(outdir, 'ancillary', f'targetphot{prefix}-zcat-{survey}-{program}-{specprod}.fits')
        miniphot_outfile = os.path.join(outdir, 'ancillary', f'targetphot{prefix}-miniphot-{survey}-{program}-{specprod}.fits')
    else:
        if healpix == '*':
            targetphot_outfile = sorted(glob(os.path.join(outdir, subdir, f'targetphot{prefix}-nside{nside}-' + \
                                                          f'hp*-{survey}-{program}-{specprod}.fits')))
            zcat_outfile = sorted(glob(os.path.join(outdir, 'ancillary', f'targetphot{prefix}-zcat-nside{nside}-' + \
                                                    f'hp*-{survey}-{program}-{specprod}.fits')))
            miniphot_outfile = sorted(glob(os.path.join(outdir, 'ancillary', f'targetphot{prefix}-miniphot-nside{nside}-' + \
                                                        f'hp*-{survey}-{program}-{specprod}.fits')))
        else:
            targetphot_outfile = os.path.join(outdir, subdir, f'targetphot{prefix}-nside{nside}-' + \
                                              f'hp{healpix:02}-{survey}-{program}-{specprod}.fits')
            zcat_outfile = os.path.join(outdir, 'ancillary', f'targetphot{prefix}-zcat-nside{nside}-' + \
                                        f'hp{healpix:02}-{survey}-{program}-{specprod}.fits')
            miniphot_outfile = os.path.join(outdir, 'ancillary', f'targetphot{prefix}-miniphot-nside{nside}-' + \
                                            f'hp{healpix:02}-{survey}-{program}-{specprod}.fits')

    return targetphot_outfile, zcat_outfile, miniphot_outfile


def read_one_zcat(catfile, potential=False, rows=None):
    """Read a single redshift catalog, e.g., ztile-sv1-dark-cumulative.fits.

    Args:
        catfile (str): full path to a given redshift catalog

    Returns an astropy.table.Table with the following columns needed to do the
    downstream matching and to enable QA: TARGETID, TILEID, TARGET_RA,
    TARGET_DEC, PETAL_LOC.

    """
    if potential:
        t0 = time.time()
        cat = Table(fitsio.read(catfile, rows=rows))
        log.info(f'Read {len(cat):,d} targets from {catfile} in {(time.time()-t0)/60.:.2f} min')
        return cat

    if rows is None:
        from desitarget.targets import decode_targetid
        t0 = time.time()
        hdr = fitsio.read_header(catfile, ext='ZCATALOG')
        survey, program = hdr['SURVEY'], hdr['PROGRAM']
        # Remove sky fibers and negative targetids (stuck fibers).
        alltargetids = fitsio.read(catfile, ext='ZCATALOG', columns='TARGETID')
        original_row = np.arange(len(alltargetids))
        _, _, _, _, sky, _ = decode_targetid(alltargetids)
        I = np.where((sky == 0) * (alltargetids > 0))[0]
        if len(I) > 0:
            cat = Table(fitsio.read(catfile, ext='ZCATALOG', rows=I, columns=[
                'TARGETID', 'TILEID', 'TARGET_RA', 'TARGET_DEC', 'PETAL_LOC']))
            original_row = original_row[I]
            # Remove duplicate observations within a given tile; e.g., in survey=sv1,
            # program=other, tileid=80870 there are 8384 observations, but only 4192 of
            # those are unique targetids.
            indx = []
            for tileid in np.unique(cat['TILEID']):
                I = np.where(tileid == cat['TILEID'])[0]
                _, uindx = np.unique(cat['TARGETID'][I], return_index=True)
                indx.append(I[uindx])
            indx = np.hstack(indx)
            cat = cat[indx]
            original_row = original_row[indx]
            cat['SURVEY'] = survey
            cat['PROGRAM'] = program
            cat['ROW'] = original_row
            log.info(f'Read {len(cat):,d}/{len(alltargetids):,d} targets from ' + \
                     f'{catfile} in {(time.time()-t0)/60.:.2f} min')
    else:
        hdr = fitsio.read_header(catfile, ext='ZCATALOG')
        survey, program = hdr['SURVEY'], hdr['PROGRAM']
        cat = Table(fitsio.read(catfile, ext='ZCATALOG', rows=rows, columns=[
            'TARGETID', 'TILEID', 'TARGET_RA', 'TARGET_DEC', 'PETAL_LOC']))
        cat['SURVEY'] = survey
        cat['PROGRAM'] = program

    return cat


def read_one_potential_targets(tileid, survey, program):
    """Read the potential targets in a given fiberassign tile.

    Args:
        tileid (int): tile ID number

    Returns an astropy.table.Table with the following columns needed downstream:
    TARGETID, RA, DEC.

    """
    from desitarget.targets import decode_targetid

    fiberassign_dir = os.path.join(os.getenv('DESI_ROOT_READONLY'), 'target', 'fiberassign', 'tiles', 'trunk')

    stileid = '{:06d}'.format(tileid)
    fiberfile = os.path.join(fiberassign_dir, stileid[:3], f'fiberassign-{stileid}.fits.gz')
    #log.info('Reading {}'.format(fiberfile))

    out = Table(fitsio.read(fiberfile, ext='TARGETS', columns=['TARGETID', 'RA', 'DEC']))

    # remove skies
    _, _, _, _, sky, _ = decode_targetid(out['TARGETID'])
    keep = (sky == 0) * (out['TARGETID'] > 0)
    out = out[keep]

    out['TILEID'] = tileid
    out['SURVEY'] = survey
    out['PROGRAM'] = program

    return out


def tractorphot_onebrick(cat, RACOLUMN='TARGET_RA', DECCOLUMN='TARGET_DEC'):
    """Wrapper on desispec.io.photo.gather_tractorphot with special handling of duplicates.

    Targets can repeat across surveys, programs, and even across tiles (within
    the same survey/program), especially between SV and main. However,
    tractorphot_onebrick needs the input sources to be unique.

    """
    from desispec.io.photo import gather_tractorphot

    # Separate out the non-DR9 targets, i.e., those with BRICK_OBJID==0, since
    # they are handled correctly in gather_tractorphot and may have DR9
    # photometry based on a positional match.
    Idr9 = np.where((cat['RELEASE'] > 0) * (cat['BRICKID'] > 0) *
                    (cat['BRICK_OBJID'] > 0) * (cat['PHOTSYS'] != ''))[0]
    Ipos = np.delete(np.arange(len(cat)), Idr9)

    cat_pos = cat[Ipos]
    cat_dr9 = cat[Idr9]
    if len(cat_dr9) > 0:
        uobjid, uindx, objcount = np.unique(cat_dr9['BRICK_OBJID'].value, return_counts=True, return_index=True)

        if len(cat_pos) > 0:
            ucat_dr9 = vstack((cat_dr9[uindx], cat_pos))
        else:
            ucat_dr9 = cat_dr9[uindx]
        # sort for speed
        ucat_dr9 = ucat_dr9[np.argsort(ucat_dr9['BRICK_OBJID'])]
        tractorphot_dr9 = gather_tractorphot(ucat_dr9, racolumn=RACOLUMN, deccolumn=DECCOLUMN)

        # Handle duplicates across surveys/programs/tiles.
        cat_dr9_dup = cat_dr9[~np.isin(cat_dr9['TARGETID'], tractorphot_dr9['TARGETID'])]
        if len(cat_dr9_dup) > 0:
            tractorphot_dr9_dup = []
            for objid, targetid in zip(cat_dr9_dup['BRICK_OBJID'].value, cat_dr9_dup['TARGETID'].value):
                I = np.where(tractorphot_dr9['OBJID'] == objid)[0]
                if len(I) > 1:
                    # Special case: BRICK_OBJID is unique on input but
                    # duplicated on output, which can happen when multiple
                    # TARGETIDs can point to the same BRICK_OBJID.

                    # E.g., on brick 3556p282, objid 4384:
                    #   sv1   bright  80616   39628446329999648
                    #   main  bright  21243   39637242423021856
                    #   main  backup  42570 2305843030558524910
                    I = I[:1]
                tractorphot_one = tractorphot_dr9[I]
                tractorphot_one['TARGETID'] = targetid
                tractorphot_dr9_dup.append(tractorphot_one)
            tractorphot_dr9_dup = vstack(tractorphot_dr9_dup)
            tractorphot = vstack((tractorphot_dr9, tractorphot_dr9_dup))
        else:
            # ...otherwise we are done.
            tractorphot = tractorphot_dr9
    else:
        # no DR9 targets at all
        if len(cat_pos) > 0:
            tractorphot = gather_tractorphot(cat_pos, racolumn=RACOLUMN, deccolumn=DECCOLUMN)

    if len(tractorphot) != len(np.unique(tractorphot['TARGETID'])):
        brickname = cat['BRICKNAME'][0]
        errmsg = f'Unexpected duplicates in brick {brickname}'
        log.critical(errmsg)
        raise ValueError(errmsg)

    indx_tractor = geomask.match_to(tractorphot['TARGETID'].value, cat['TARGETID'].value)
    tractorphot = tractorphot[indx_tractor]
    assert(np.all(tractorphot['TARGETID'] == cat['TARGETID']))

    return tractorphot


def targetphot_onetile(input_cat, racolumn='TARGET_RA', deccolumn='TARGET_DEC'):
    """Simple wrapper on desispec.io.photo.gather_targetphot."""
    from desispec.io.photo import gather_targetphot
    from desiutil.names import radec_to_desiname

    # should be unique!
    assert(len(input_cat) == len(np.unique(input_cat['TARGETID'])))

    targetphot = gather_targetphot(input_cat, racolumn=racolumn, deccolumn=deccolumn, verbose=False)

    # Can have the same targetid across different surveys and even within a
    # survey, across different tiles. So we need these columns.
    # See https://github.com/moustakas/desi-photometry/issues/3
    targetphot['SURVEY'] = input_cat['SURVEY']
    targetphot['PROGRAM'] = input_cat['PROGRAM']
    targetphot['TILEID'] = input_cat['TILEID']
    targetphot['DESINAME'] = radec_to_desiname(targetphot['RA'], targetphot['DEC'])

    # Replace proper-motion NaNs with zeros.
    inan = np.logical_or(np.isnan(targetphot['PMRA']), np.isnan(targetphot['PMDEC']))
    if np.any(inan):
        targetphot['PMRA'][inan] = 0.0
        targetphot['PMDEC'][inan] = 0.0

    return targetphot


def write_tractorphot(tractorphot, miniphot=None, outfile=None,
                      nside=None, healpix=None, sort=True):
    """Simple wrapper to write out a tractorphot catalog.

    """
    if tractorphot is not None and miniphot is not None:
        if sort:
            # not all targets have Tractor photometry
            indx_tractor, indx_mini = geomask.match(tractorphot['TARGETID'], miniphot['TARGETID'])
            tractorphot = tractorphot[indx_tractor]
            miniphot = miniphot[indx_mini]

        if not np.all(tractorphot['TARGETID'] == miniphot['TARGETID']):
            errmsg = f'Mismatching tractorphot and miniphot catalogs!'
            log.critical(errmsg)
            raise ValueError(errmsg)

    if outfile is not None:
        add_dependencies(tractorphot.meta, envvar_names=['DESI_ROOT', 'DESI_ROOT_READONLY'],
                         module_names=possible_dependencies)

        if nside is not None and healpix is not None:
            tractorphot.meta['FILENSID'] = (nside, 'HEALPix nside number')
            tractorphot.meta['FILENEST'] = (True, 'HEALPix nested (not ring) ordering')
            tractorphot.meta['FILEHPIX'] = (healpix, 'HEALPix number')
        else:
            for popkey in ['FILENSID', 'FILENEST', 'FILEHPIX']:
                if popkey in tractorphot.meta.keys():
                    tractorphot.meta.pop(popkey)

        tractorphot.meta['EXTNAME'] = 'TRACTORPHOT'

    igood = np.where(tractorphot['BRICKNAME'] != '')[0]
    if len(igood) > 0:
        t0 = time.time()
        tractorphot[igood].write(outfile, overwrite=True)
        log.info(f'Writing {len(igood):,d} targets to {outfile} took {time.time()-t0:.1f} sec')

    inone = np.where(tractorphot['BRICKNAME'] == '')[0]
    if len(inone) > 0:
        log.info(f'No Tractor photometry found for {len(inone):,d}/{len(tractorphot):,d} targets')


def write_targetphot(targetphot=None, zcat=None, miniphot=None, survey=None,
                     program=None, targetphot_outfile=None, zcat_outfile=None,
                     miniphot_outfile=None, sort=True, nside=None, healpix=None):
    """Simple wrapper to write out a targetphot catalog and its ancillary catalogs.

    """
    # Optionally row-match targetphot_program to zcat_program, taking into account
    # that, e.g., since different ranks can finish at different times and
    # targetids can repeat across tiles, we need to sort on a tileid-targetid
    # key.
    if targetphot is not None and zcat is not None:
        if sort:
            zkey = [f'{tile}-{tid}' for tile, tid in zip(zcat['TILEID'], zcat['TARGETID'])]
            tkey = [f'{tile}-{tid}' for tile, tid in zip(targetphot['TILEID'], targetphot['TARGETID'])]
            zsrt = geomask.match_to(tkey, zkey)
            targetphot = targetphot[zsrt]

        if not np.all(targetphot['TARGETID'] == zcat['TARGETID']):
            errmsg = f'Mismatching targetphot and zcat catalogs!'
            log.critical(errmsg)
            raise ValueError(errmsg)


    if targetphot is not None:
        # remove extraneous targeting bits -
        # https://github.com/moustakas/desi-photometry/issues/13
        if survey == 'main' or survey == 'special':
            remcols = ['CMX_TARGET',
                       'SV1_DESI_TARGET', 'SV1_BGS_TARGET', 'SV1_MWS_TARGET',
                       'SV2_DESI_TARGET', 'SV2_BGS_TARGET', 'SV2_MWS_TARGET',
                       'SV3_DESI_TARGET', 'SV3_BGS_TARGET', 'SV3_MWS_TARGET',
                       'SV1_SCND_TARGET', 'SV2_SCND_TARGET','SV3_SCND_TARGET']
            for remcol in remcols:
                if remcol in targetphot.colnames:
                    targetphot.remove_column(remcol)

        if targetphot_outfile is not None:
            add_dependencies(targetphot.meta, envvar_names=['DESI_ROOT', 'DESI_ROOT_READONLY'],
                             module_names=possible_dependencies)
            if survey is not None:
                targetphot.meta['SURVEY'] = (survey, 'survey name')
            else:
                if 'SURVEY' in targetphot.meta.keys():
                    targetphot.meta.pop('SURVEY')

            if program is not None:
                targetphot.meta['PROGRAM'] = (program, 'program name')
            else:
                if 'PROGRAM' in targetphot.meta.keys():
                    targetphot.meta.pop('PROGRAM')

            if nside is not None and healpix is not None:
                targetphot.meta['FILENSID'] = (nside, 'HEALPix nside number')
                targetphot.meta['FILENEST'] = (True, 'HEALPix nested (not ring) ordering')
                targetphot.meta['FILEHPIX'] = (healpix, 'HEALPix number')
            else:
                for popkey in ['FILENSID', 'FILENEST', 'FILEHPIX']:
                    if popkey in targetphot.meta.keys():
                        targetphot.meta.pop(popkey)

            targetphot.meta['EXTNAME'] = 'TARGETPHOT'

            t0 = time.time()
            targetphot.write(targetphot_outfile, overwrite=True)
            log.info(f'Writing {len(targetphot):,d} targets to {targetphot_outfile} took {time.time()-t0:.1f} sec')

        if survey is not None and 'SURVEY' not in targetphot.colnames:
            targetphot['SURVEY'] = survey
        if program is not None and 'PROGRAM' not in targetphot.colnames:
            targetphot['PROGRAM'] = program

        # Build a "mini" ancillary catalog that we will use to query the Tractor
        # catalogs, below.
        miniphot = targetphot[MINIPHOT_COLUMNS]

    if miniphot is not None and miniphot_outfile is not None:
        add_dependencies(miniphot.meta, envvar_names=['DESI_ROOT', 'DESI_ROOT_READONLY'],
                         module_names=possible_dependencies)

        if survey is not None:
            miniphot.meta['SURVEY'] = (survey, 'survey name')
        else:
            if 'SURVEY' in miniphot.meta.keys():
                miniphot.meta.pop('SURVEY')

        if program is not None:
            miniphot.meta['PROGRAM'] = (program, 'program name')
        else:
            if 'PROGRAM' in targetphot.meta.keys():
                miniphot.meta.pop('PROGRAM')

        if nside is not None and healpix is not None:
            miniphot.meta['FILENSID'] = (nside, 'HEALPix nside number')
            miniphot.meta['FILENEST'] = (True, 'HEALPix nested (not ring) ordering')
            miniphot.meta['FILEHPIX'] = (healpix, 'HEALPix number')
        else:
            for popkey in ['FILENSID', 'FILENEST', 'FILEHPIX']:
                if popkey in miniphot.meta.keys():
                    miniphot.meta.pop(popkey)

        miniphot.meta['EXTNAME'] = 'MINIPHOT'
        t0 = time.time()
        miniphot.write(miniphot_outfile, overwrite=True)
        log.info(f'Writing {len(miniphot):,d} targets to {miniphot_outfile} took {time.time()-t0:.1f} sec')


    if zcat is not None and zcat_outfile is not None:
        add_dependencies(zcat.meta, envvar_names=['DESI_ROOT', 'DESI_ROOT_READONLY'],
                         module_names=possible_dependencies)
        if survey is not None:
            zcat.meta['SURVEY'] = (survey, 'survey name')
        else:
            if 'SURVEY' in zcat.meta.keys():
                zcat.meta.pop('SURVEY')

        if program is not None:
            zcat.meta['PROGRAM'] = (program, 'program name')
        else:
            if 'PROGRAM' in zcat.meta.keys():
                zcat.meta.pop('PROGRAM')

        zcat.meta['EXTNAME'] = 'ZCATALOG'

        t0 = time.time()
        zcat.write(zcat_outfile, overwrite=True)
        log.info(f'Writing {len(zcat):,d} targets to {zcat_outfile} took {time.time()-t0:.1f} sec')

    return targetphot, zcat, miniphot


def targetphot(specprod, zcatdir, outdir, comm=None, mp=1, nside=1,
               surveys=ALLSURVEYS, programs=ALLPROGRAMS,
               debug_ntiles=None, overwrite=False, potential=False):
    """Gather targeting photometry for observed and potential targets.

    """
    if comm is None:
        rank, size = 0, 1
    else:
        rank, size = comm.rank, comm.size

    if potential:
        RACOLUMN, DECCOLUMN = 'RA', 'DEC'
        targets_subdir = 'potential-targets'
        suffix = '-potential'
    else:
        RACOLUMN, DECCOLUMN = 'TARGET_RA', 'TARGET_DEC'
        targets_subdir = 'observed-targets'
        suffix = ''

    if rank == 0:
        tall = time.time()

        if not os.path.isdir(os.path.join(outdir, targets_subdir)):
            os.makedirs(os.path.join(outdir, targets_subdir), exist_ok=True)
        if not os.path.isdir(os.path.join(outdir, 'ancillary')):
            os.makedirs(os.path.join(outdir, 'ancillary'), exist_ok=True)

    # Divide by survey.
    for survey in surveys:
        if rank == 0:
            tsurvey = time.time()

        #  Divide by program.
        for program in programs:
            if rank == 0:
                tprogram = time.time()
                log.info(f'Working on {survey}:{program} ({targets_subdir})')

            if potential:
                _, zcatfile, _ = get_targetphot_filenames(
                    survey, program, specprod, outdir=outdir, potential=False)
            else:
                zcatfile = os.path.join(zcatdir, f'ztile-{survey}-{program}-cumulative.fits')

            if not os.path.isfile(zcatfile):
                if rank == 0:
                    log.warning(f'No redshift catalog {zcatfile} found')
                continue

            # Are we already done? All surveys/programs except
            # main/{bright,dark,backup} have merged catalogs.
            targetphot_outfile, _, _ = get_targetphot_filenames(
                survey, program, specprod, outdir=outdir, potential=potential)
            if survey == 'main':
                pass
            else:
                if os.path.isfile(targetphot_outfile) and not overwrite:
                    if rank == 0:
                        log.info(f'Skipping existing targetphot file {targetphot_outfile}')
                    continue

            # Initialize the variables we will be broadcasting.
            if comm is not None and size > 1:
                pixels_todo = None

            # Read the appropriate redshift catalog on rank 0.
            if rank == 0:
                zcat_program = read_one_zcat(zcatfile, potential=potential)

                # Optionally test with a smaller number of tiles.
                if debug_ntiles is not None:
                    print('Debugging with a smaller sample...')
                    utiles = np.unique(zcat_program['TILEID'])
                    if len(utiles) > 1:
                        I = np.random.choice(len(utiles), debug_ntiles, replace=False)
                        zcat_program = zcat_program[np.isin(zcat_program['TILEID'], utiles[I])]

                allpixels = radec2pix(nside, zcat_program['TARGET_RA'], zcat_program['TARGET_DEC'])
                upixels = sorted(set(allpixels))
                #upixels = [8, 9, 30, 31] # for testing
                log.info(f'Dividing the sample into {len(upixels)} nside={nside} healpixel(s)')

                # Loop on healpix
                pixels_todo = []
                for ipix, pixel in enumerate(upixels):
                    targetphot_outfile, zcat_outfile, miniphot_outfile = get_targetphot_filenames(
                        survey, program, specprod, outdir=outdir, healpix=pixel, nside=nside,
                        potential=potential)
                    if os.path.isfile(targetphot_outfile) and not overwrite:
                        log.warning(f'Skipping existing targetphot file {targetphot_outfile}')
                        continue

                    # If using MPI-parallelization, just keep track of the
                    # healpix number.
                    if comm is not None and size > 1:
                        pixels_todo.append(pixel)
                    else:
                        P = np.where(pixel == allpixels)[0]
                        zcat_pixel = zcat_program[P]
                        utiles_onepixel = np.unique(zcat_pixel['TILEID'].value)

                        # ...otherwise just loop on the unique set of tiles and write out.
                        log.info(f'Pixel {pixel:03} ({ipix+1:03}/{len(upixels):03}): working on {len(zcat_pixel):,d} ' + \
                                 f'targets and {len(utiles_onepixel):,d} unique tiles')
                        targetphot_pixel = []
                        for tileid in utiles_onepixel:
                            if potential:
                                potential_targets = read_one_potential_targets(tileid, survey, program)
                                # filter to the set of potential targets on this healpixel
                                I = np.where(radec2pix(nside, potential_targets['RA'], potential_targets['DEC']) == pixel)[0]
                                potential_targets = potential_targets[I]
                                _targetphot_onetile = targetphot_onetile(potential_targets, RACOLUMN, DECCOLUMN)
                            else:
                                I = np.where(tileid == zcat_pixel['TILEID'].value)[0]
                                _targetphot_onetile = targetphot_onetile(zcat_pixel[I], RACOLUMN, DECCOLUMN)
                            targetphot_pixel.append(_targetphot_onetile)

                        targetphot_pixel = vstack(targetphot_pixel)
                        if potential:
                            targetphot_pixel, _, miniphot_pixel = write_targetphot(
                                targetphot_pixel, targetphot_outfile=targetphot_outfile,
                                miniphot_outfile=miniphot_outfile, survey=survey, program=program,
                                healpix=pixel, nside=nside)
                        else:
                            targetphot_pixel, zcat_pixel, miniphot_pixel = write_targetphot(
                                targetphot_pixel, zcat=zcat_pixel, targetphot_outfile=targetphot_outfile,
                                zcat_outfile=zcat_outfile, miniphot_outfile=miniphot_outfile,
                                survey=survey, program=program, healpix=pixel, nside=nside, sort=True)


            # If parallelizing, broadcast the list of pixels to process.
            if comm is not None and size > 1:
                pixels_todo = comm.bcast(pixels_todo, root=0)

                for ipix, pixel in enumerate(pixels_todo):
                    # Rank 0 sends the portion of the miniphot catalog that every other
                    # rank should be working on.
                    if rank == 0:
                        tone = time.time()
                        log.info(f'Working on healpix {pixel:03} ({ipix+1:03}/{len(pixels_todo):03}) ')

                        P = np.where(pixel == allpixels)[0]
                        zcat_pixel = zcat_program[P]
                        alltiles_pixel = zcat_pixel['TILEID'].value
                        utiles_pixel = np.unique(alltiles_pixel)
                        utiles_byrank = np.array_split(utiles_pixel, size-1)

                        if potential:
                            log.info(f'Distributing {len(utiles_pixel):,d} unique tiles to {size-1} ranks')
                        else:
                            log.info(f'Distributing {len(P):,d} targets from {len(utiles_pixel):,d} ' + \
                                     f'unique tiles to {size-1} ranks')

                        for onerank, utiles in zip(np.arange(size-1)+1, utiles_byrank):
                            rows_pixel = np.where(np.isin(alltiles_pixel, utiles))[0]
                            if potential:
                                log.debug(f'Rank {rank:03} distributing to rank {onerank:03}: ' + \
                                          f'{len(rows_pixel):,d} {len(utiles):,d} unique tiles')
                            else:
                                log.debug(f'Rank {rank:03} distributing to rank {onerank:03}: {len(rows_pixel):,d} ' + \
                                          f'targets from {len(utiles):,d} unique tiles')
                            comm.send(zcat_pixel[rows_pixel], dest=onerank)

                    # Ranks >0 receive their mini-catalog, generate the
                    # per-tile targetphot catalogs, and then send the stacked
                    # results back to rank 0...
                    if rank > 0:
                        zcat_manytiles = comm.recv(source=0)
                        log.debug(f'Rank {rank:03}: received {len(zcat_manytiles):,d} targets from rank 000')
                        if len(zcat_manytiles) == 0: # no work to do
                            comm.send(Table(), dest=0)
                        else:
                            targetphot_onerank = []
                            # now loop through unique tiles
                            alltiles = zcat_manytiles['TILEID'].value
                            for tileid in np.unique(alltiles):
                                if potential:
                                    potential_targets = read_one_potential_targets(tileid, survey, program)
                                    # filter to the set of potential targets on this healpixel
                                    I = np.where(radec2pix(nside, potential_targets['RA'], potential_targets['DEC']) == pixel)[0]
                                    potential_targets = potential_targets[I]
                                    _targetphot_onetile = targetphot_onetile(potential_targets, RACOLUMN, DECCOLUMN)
                                else:
                                    I = np.where(tileid == alltiles)[0]
                                    _targetphot_onetile = targetphot_onetile(zcat_manytiles[I], RACOLUMN, DECCOLUMN)
                                targetphot_onerank.append(_targetphot_onetile)
                            targetphot_onerank = vstack(targetphot_onerank)
                            log.debug(f'Rank {rank:03} sending to rank 000: targeting photometry ' + \
                                      f'for {len(targetphot_onerank):,d} targets')
                            comm.send(targetphot_onerank, dest=0)
                    else:
                        targetphot_pixel = []
                        # ...while rank 0 receives them.
                        for onerank in np.arange(size-1)+1:
                            targetphot_onerank = comm.recv(source=onerank)
                            log.debug(f'Rank {rank:03}: received targeting photometry for ' + \
                                      f'{len(targetphot_onerank):,d} targets from rank {onerank:03}')
                            if len(targetphot_onerank) > 0:
                                targetphot_pixel.append(targetphot_onerank)

                    comm.barrier()

                    # sort and write out on rank 0
                    if rank == 0:
                        # This is only empty if all the catalogs already exist,
                        # which is fine.
                        if len(targetphot_pixel) > 0:
                            targetphot_pixel = vstack(targetphot_pixel)
                            log.info(f'Gathering target photometry for {len(targetphot_pixel):,d} ' + \
                                     f'targets took {(time.time()-tone)/60.:.3f} min')

                            targetphot_outfile, zcat_outfile, miniphot_outfile = get_targetphot_filenames(
                                survey, program, specprod, outdir=outdir, healpix=pixel, nside=nside,
                                potential=potential)

                            if potential:
                                targetphot_pixel, _, miniphot_pixel = write_targetphot(
                                    targetphot_pixel, targetphot_outfile=targetphot_outfile,
                                    miniphot_outfile=miniphot_outfile, survey=survey, program=program,
                                    healpix=pixel, nside=nside)
                            else:
                                targetphot_pixel, zcat_pixel, mini_pixel = write_targetphot(
                                    targetphot_pixel, zcat=zcat_pixel, targetphot_outfile=targetphot_outfile,
                                    zcat_outfile=zcat_outfile, miniphot_outfile=miniphot_outfile,
                                    survey=survey, program=program, healpix=pixel, nside=nside, sort=True)


            if rank == 0:
                # For all surveys except 'main'/{bright,dark}, gather up the
                # individual healpix files and merge them. Always gather up the
                # 'miniphot' catalogs and, if potential=False, the 'zcat'
                # catalogs.
                t0 = time.time()
                targetphot_files, zcat_files, miniphot_files = get_targetphot_filenames(
                    survey, program, specprod, outdir=outdir, healpix='*', nside=nside,
                    potential=potential)
                targetphot_outfile, zcat_outfile, miniphot_outfile = get_targetphot_filenames(
                    survey, program, specprod, outdir=outdir, potential=potential)

                miniphot_program = []
                for miniphot_file in miniphot_files:
                    miniphot_program.append(Table(fitsio.read(miniphot_file)))
                    os.remove(miniphot_file)
                if len(miniphot_program) > 0:
                    miniphot_program = vstack(miniphot_program)

                if potential:
                    zcat_program = None
                else:
                    zcat_program = []
                    for zcat_file in zcat_files:
                        zcat_program.append(Table(fitsio.read(zcat_file)))
                        os.remove(zcat_file)
                    if len(zcat_program) > 0:
                        zcat_program = vstack(zcat_program)

                if survey == 'main':
                    if potential:
                        log.info(f'Gathering individual miniphot catalogs took {time.time()-t0:.1f} sec')
                    else:
                        log.info(f'Gathering individual miniphot and zcat catalogs took {time.time()-t0:.1f} sec')
                    if len(miniphot_program) > 0:
                        write_targetphot(zcat=zcat_program, miniphot=miniphot_program,
                                         zcat_outfile=zcat_outfile,
                                         miniphot_outfile=miniphot_outfile,
                                         survey=survey, program=program)
                else:
                    targetphot_program = []
                    for targetphot_file in targetphot_files:
                        targetphot_program.append(Table(fitsio.read(targetphot_file)))
                        os.remove(targetphot_file)
                    if len(targetphot_program) > 0:
                        targetphot_program = vstack(targetphot_program)

                    log.info(f'Gathering individual targetphot, miniphot, and zcat catalogs took {time.time()-t0:.1f} sec')
                    if len(targetphot_program) > 0:
                        write_targetphot(targetphot_program, zcat=zcat_program,
                                         miniphot=miniphot_program,
                                         targetphot_outfile=targetphot_outfile,
                                         zcat_outfile=zcat_outfile,
                                         miniphot_outfile=miniphot_outfile,
                                         survey=survey, program=program, sort=True)

                log.info(f'Total time for {survey}:{program} ({targets_subdir}): {(time.time()-tprogram)/60.:.2f} min')

        if rank == 0:
            log.info(f'Total time for all programs in {survey} ({targets_subdir}): {(time.time()-tsurvey)/60.:.2f} min')

    if rank == 0:
        log.info(f'Total time for all surveys ({targets_subdir}): {(time.time()-tall)/60.:.2f} min')

    if comm is not None:
        comm.barrier()


def tractorphot(specprod, outdir, comm=None, mp=1, nside=4, potential=False,
                surveys=ALLSURVEYS, programs=ALLPROGRAMS, overwrite=False):
    """Gather targeting photometry for observed targets.

    """
    from desitarget.targets import decode_targetid
    from desiutil.brick import brickname as get_brickname
    from desispec.parallel import weighted_partition

    if comm is None:
        rank, size = 0, 1
    else:
        rank, size = comm.rank, comm.size

    RACOLUMN, DECCOLUMN = 'RA', 'DEC'
    if potential:
        targets_subdir = 'potential-targets'
        suffix = '-potential'
    else:
        targets_subdir = 'observed-targets'
        suffix = ''

    miniphot_filename = os.path.join(outdir, 'ancillary', f'targetphot{suffix}-miniphot-{specprod}.fits')
    #nbricks_per_chunk = 30

    # Initialize the variables we will be broadcasting.
    if comm is not None and size > 1:
        pixels_todo = None

    if rank == 0:
        tall = time.time()
        log.info(f'Gathering Tractor photometry ({targets_subdir})')

        if not os.path.isdir(os.path.join(outdir, targets_subdir, 'tractorphot')):
            os.makedirs(os.path.join(outdir, targets_subdir, 'tractorphot'), exist_ok=True)

        # Gather up the miniphot catalogs across all surveys and programs.
        if not os.path.isfile(miniphot_filename) or overwrite:
            t0 = time.time()
            miniphot = []
            for survey in surveys:
                for program in programs:
                    _, _, miniphot_file = get_targetphot_filenames(survey, program, specprod, outdir=outdir, potential=potential)
                    if os.path.isfile(miniphot_file): # not all survey-program combinations exist
                        mini = Table(fitsio.read(miniphot_file))
                        log.info(f'Read {len(mini):,d} targets from {miniphot_file}')
                        miniphot.append(mini)
            miniphot = vstack(miniphot)
            nobj = len(miniphot)

            # TARGETIDs can repeat in and between surveys, so select just unique
            # targets here; that's fine.
            _, uindx = np.unique(miniphot['TARGETID'], return_index=True)
            miniphot = miniphot[uindx]

            # Some secondary programs (e.g., 39632961435338613, 39632966921487347)
            # have BRICKNAME!='' & BRICKID!=0, but BRICK_OBJID==0. Unpack those here
            # using decode_targetid.
            fix = np.where((miniphot['BRICKNAME'] != '') * (miniphot['BRICK_OBJID'] == 0))[0]
            if len(fix) > 0:
                log.debug(f'Inferring BRICK_OBJID for {len(fix):,d}/{len(miniphot):,d} targets using decode_targetid')
                fix_objid, fix_brickid, _, _, _, _ = decode_targetid(miniphot['TARGETID'][fix])
                assert(np.all(fix_brickid == miniphot['BRICKID'][fix]))
                miniphot['BRICK_OBJID'][fix] = fix_objid

            inobrickname = np.where(miniphot['BRICKNAME'] == '')[0]
            if len(inobrickname) > 0:
                log.debug(f'Inferring brickname for {len(inobrickname):,d}/{len(miniphot):,d} targets')
                miniphot['BRICKNAME'][inobrickname] = get_brickname(miniphot[RACOLUMN][inobrickname],
                                                                    miniphot[DECCOLUMN][inobrickname])
            assert(np.all(miniphot['BRICKNAME'] != ''))

            # sort by brickname
            srt = np.argsort(miniphot['BRICKNAME'])
            miniphot = miniphot[srt]
            log.info(f'Generated merged miniphot catalog for {len(miniphot):,d}/{nobj:,d} unique ' + \
                     f'targets in {(time.time()-t0)/60.:.2f} min')

            # write out a merged 'miniphot' catalog
            #miniphot['ROW'] = np.arange(len(miniphot))
            t0 = time.time()
            miniphot.write(miniphot_filename, overwrite=True)
            log.info(f'Wrote {len(miniphot):,d} targets to {miniphot_filename} in {(time.time()-t0)/60.:.2f} min')
        else:
            t0 = time.time()
            miniphot = Table(fitsio.read(miniphot_filename))
            log.info(f'Read {len(miniphot):,d} targets from merged miniphot catalog ' + \
                     f'{miniphot_filename} in {(time.time()-t0)/60.:.2f} min')

        # Divide the sample into nside healpixels.
        allpixels = radec2pix(nside, miniphot[RACOLUMN].value, miniphot[DECCOLUMN].value)
        upixels = sorted(set(allpixels))
        #upixels = [1] # for testing
        log.info(f'Dividing the sample into {len(upixels)} nside={nside} healpixel(s)')

        pixels_todo = []
        for ipix, pixel in enumerate(upixels):
            tractorphot_outfile = get_tractorphot_filename(
                specprod, nside, pixel, outdir=outdir, potential=potential)
            if os.path.isfile(tractorphot_outfile) and not overwrite:
                log.warning(f'Skipping existing tractorphot file {tractorphot_outfile}')
                continue

            # If using MPI-parallelization, just keep track of the healpix
            # number...
            if comm is not None and size > 1:
                pixels_todo.append(pixel)
            else:
                P = np.where(pixel == allpixels)[0]
                miniphot_pixel = miniphot[P]
                ubricks_onepixel = np.unique(miniphot_pixel['BRICKNAME'].value)

                # ...otherwise just loop on the unique set of bricks and write out.
                log.info(f'Pixel {pixel:03} ({ipix+1:03}/{len(upixels):03}): working on {len(miniphot_pixel):,d} ' + \
                         f'targets and {len(ubricks_onepixel):,d} unique bricks.')

                tractorphot_pixel = []
                for brick in ubricks_onepixel:
                    I = np.where(brick == miniphot_pixel['BRICKNAME'].value)[0]
                    _tractorphot_onebrick = tractorphot_onebrick(miniphot_pixel[I], RACOLUMN, DECCOLUMN)
                    tractorphot_pixel.append(_tractorphot_onebrick)

                tractorphot_pixel = vstack(tractorphot_pixel)
                write_tractorphot(tractorphot_pixel, miniphot=miniphot_pixel, healpix=pixel,
                                  nside=nside, outfile=tractorphot_outfile, sort=True)


    # If parallelizing, broadcast the list of pixels to process.
    if comm is not None and size > 1:
        pixels_todo = comm.bcast(pixels_todo, root=0)

        #for ipix, pixel in enumerate([2]):
        for ipix, pixel in enumerate(pixels_todo):

            # Rank 0 sends the portion of the miniphot catalog that every other
            # rank should be working on.
            if rank == 0:
                tone = time.time()
                log.info(f'Working on healpix {pixel:03} ({ipix+1:03}/{len(pixels_todo):03}) ')

                P = np.where(pixel == allpixels)[0]
                miniphot_pixel = miniphot[P]
                allbricks_pixel = miniphot_pixel['BRICKNAME'].value
                ubricks_pixel = np.unique(allbricks_pixel)
                ubricks_byrank = np.array_split(ubricks_pixel, size-1)

                log.info(f'Distributing {len(P):,d} targets from {len(ubricks_pixel):,d} unique bricks to {size-1} ranks')

                for onerank, ubricks in zip(np.arange(size-1)+1, ubricks_byrank):
                    rows_pixel = np.where(np.isin(allbricks_pixel, ubricks))[0]
                    log.debug(f'Rank {rank:03} distributing to rank {onerank:03}: {len(rows_pixel):,d} ' + \
                              f'targets from {len(ubricks):,d} unique bricks')
                    comm.send(miniphot_pixel[rows_pixel], dest=onerank)

            # Ranks >0 receive their mini-catalog, generate the per-brick
            # tractorphot catalogs, and then send the stacked results back to
            # rank 0...
            if rank > 0:
                miniphot_manybricks = comm.recv(source=0)
                log.debug(f'Rank {rank:03}: received {len(miniphot_manybricks):,d} targets from rank 000')
                if len(miniphot_manybricks) == 0: # no work to do
                    comm.send(Table(), dest=0)
                else:
                    tractorphot_onerank = []
                    # now loop through unique bricks
                    allbricks = miniphot_manybricks['BRICKNAME'].value
                    for brick in np.unique(allbricks):
                        I = np.where(brick == allbricks)[0]
                        _tractorphot_onebrick = tractorphot_onebrick(miniphot_manybricks[I], RACOLUMN, DECCOLUMN)
                        tractorphot_onerank.append(_tractorphot_onebrick)
                    tractorphot_onerank = vstack(tractorphot_onerank)
                    log.debug(f'Rank {rank:03} sending to rank 000: Tractor photometry ' + \
                              f'for {len(tractorphot_onerank):,d} targets')
                    comm.send(tractorphot_onerank, dest=0)
            else:
                tractorphot_pixel = []
                # ...while rank 0 receives them.
                for onerank in np.arange(size-1)+1:
                    tractorphot_onerank = comm.recv(source=onerank)
                    log.debug(f'Rank {rank:03}: received Tractor photometry for ' + \
                              f'{len(tractorphot_onerank):,d} targets from rank {onerank:03}')
                    if len(tractorphot_onerank) > 0:
                        tractorphot_pixel.append(tractorphot_onerank)

            comm.barrier()

            # sort and write out on rank 0
            if rank == 0:
                # This is only empty if all the catalogs already exist,
                # which is fine.
                if len(tractorphot_pixel) > 0:
                    tractorphot_pixel = vstack(tractorphot_pixel)
                    log.info(f'Gathering Tractor photometry for {len(tractorphot_pixel):,d} ' + \
                             f'targets took {(time.time()-tone)/60.:.3f} min')

                    P = np.where(pixel == allpixels)[0]
                    miniphot_pixel = miniphot[P]

                    tractorphot_outfile = get_tractorphot_filename(
                        specprod, nside, pixel, outdir=outdir, potential=potential)

                    write_tractorphot(tractorphot_pixel, miniphot=miniphot_pixel,
                                      outfile=tractorphot_outfile, nside=nside,
                                      healpix=pixel, sort=True)

            comm.barrier()


    if rank == 0:
        log.info(f'Total time for tractorphot ({targets_subdir}): {(time.time()-tall)/60.:.3f} min')

    ## remove temporary miniphot catalog
    #log.info(f'Removing {miniphot_filename}')
    #os.remove(miniphot_filename)

    # For testing and validation, gather the set of targets "missing" LS/DR9
    # photometry.
    if rank == 0:
        tmiss = time.time()

        missing = []
        for pixel in upixels:
            log.debug(f'Gathering missing targets on healpix {pixel:03}')

            tractorphot_outfile = get_tractorphot_filename(
                specprod, nside, pixel, outdir=outdir, potential=potential)

            P = np.where(pixel == allpixels)[0]
            if os.path.isfile(tractorphot_outfile):
                _targetid = fitsio.read(tractorphot_outfile, columns='TARGETID')
                imiss = np.where(np.logical_not(np.isin(miniphot['TARGETID'][P], _targetid)))[0]
                if len(imiss) > 0:
                    missing.append(miniphot[P[imiss]])
            else:
                # all targets are missing
                missing.append(miniphot[P])

        nmissing = len(missing)
        if nmissing == 0:
            log.info(f'No targets with missing Tractor photometry ({targets_subdir})')
        else:
            missing = vstack(missing)
            missing_outfile = os.path.join(outdir, 'ancillary', f'targetphot{suffix}-missing-{specprod}.fits')
            add_dependencies(missing.meta, envvar_names=['DESI_ROOT', 'DESI_ROOT_READONLY'],
                         module_names=possible_dependencies)
            missing.meta['EXTNAME'] = 'TARGETPHOT'
            t0 = time.time()
            log.info(f'Writing {len(missing):,d} targets to {missing_outfile} took {(time.time()-t0)/60.:.3f} min')
            missing.write(missing_outfile, overwrite=True)

        log.info('Gathering targets with missing Tractor photometry ' + \
                 f'({targets_subdir}) took {(time.time()-tmiss)/60.:.3f} min')

    if comm is not None:
        comm.barrier()


def main():
    """Main wrapper.

    """
    import argparse

    parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    parser.add_argument('--specprod', type=str, required=True, help='Spectroscopic production; output file prefix.')
    parser.add_argument('--zcatdir', type=str, required=True, help='Redshift catalog base directory.')
    parser.add_argument('--surveys', type=str, default=','.join(ALLSURVEYS), help='Comma-separated list of surveys to process.')
    parser.add_argument('--programs', type=str, default=','.join(ALLPROGRAMS), help='Comma-separated list of programs to process.')
    parser.add_argument('--outdir', default='$PSCRATCH/lsdr9', type=str, help='Base output data directory.')

    parser.add_argument('--targetphot', action='store_true', help='Build the observed targets targeting catalogs.')
    parser.add_argument('--tractorphot', action='store_true', help='Build the observed targets tractor catalogs.')
    parser.add_argument('--targetphot-potential', action='store_true', help='Build the potential targets targeting catalogs.')
    parser.add_argument('--tractorphot-potential', action='store_true', help='Build the potential targets tractor catalogs.')

    parser.add_argument('--validate-targetphot', action='store_true', help='Validate the targetphot catalogs.')
    parser.add_argument('--validate-tractorphot', action='store_true', help='Validate the photo-tractor catalogs.')

    parser.add_argument('--mp', type=int, default=1, help='Number of multiprocessing processes per MPI rank or node (deprecated).')
    parser.add_argument('--debug-ntiles', type=int, default=None, help='Debug with a smaller number of (test) tiles, e.g., --debug-ntiles=10.')
    parser.add_argument('--nside-tractorphot-observed', type=int, default=4, help='healpix nside for tractorphot-observed catalogs.')
    parser.add_argument('--nside-tractorphot-potential', type=int, default=8, help='healpix nside for tractorphot-potential catalogs.')
    parser.add_argument('--nside-targetphot-observed', type=int, default=1, help='healpix nside for targetphot-observed catalogs.')
    parser.add_argument('--nside-targetphot-potential', type=int, default=2, help='healpix nside for targetphot-potential catalogs.')

    parser.add_argument('--nompi', action='store_true', help='Do not use MPI parallelism.')
    parser.add_argument('--overwrite', action='store_true', help='Overwrite existing files; use with care.')

    args = parser.parse_args()

    args.outdir = os.path.expandvars(args.outdir)
    if not os.path.isdir(args.outdir):
        os.makedirs(args.outdir, exist_ok=True)

    if args.nompi:
        comm = None
    else:
        try:
            from mpi4py import MPI
            comm = MPI.COMM_WORLD
        except ImportError:
            comm = None

    # https://docs.nersc.gov/development/languages/python/parallel-python/#use-the-spawn-start-method
    if args.mp > 1 and 'NERSC_HOST' in os.environ:
        import multiprocessing
        multiprocessing.set_start_method('spawn')

    args.surveys = np.atleast_1d(args.surveys.split(','))
    args.programs = np.atleast_1d(args.programs.split(','))

    if args.targetphot:
        targetphot(args.specprod, args.zcatdir, args.outdir, comm=comm,
                   nside=args.nside_targetphot_observed, surveys=args.surveys,
                   programs=args.programs, debug_ntiles=args.debug_ntiles,
                   overwrite=args.overwrite, potential=False)

    if args.targetphot_potential:
        targetphot(args.specprod, args.zcatdir, args.outdir, comm=comm,
                   nside=args.nside_targetphot_potential, surveys=args.surveys,
                   programs=args.programs, debug_ntiles=args.debug_ntiles,
                   overwrite=args.overwrite, potential=True)

    if args.tractorphot:
        tractorphot(args.specprod, args.outdir, comm=comm,
                    surveys=args.surveys, programs=args.programs,
                    nside=args.nside_tractorphot_observed,
                    overwrite=args.overwrite, potential=False)

    if args.tractorphot_potential:
        tractorphot(args.specprod, args.outdir, comm=comm,
                    surveys=args.surveys, programs=args.programs,
                    nside=args.nside_tractorphot_potential,
                    overwrite=args.overwrite, potential=True)


if __name__ == '__main__':
    main()
