#!/usr/bin/env python

"""Validate the files generated by lsdr9-photometry

/global/homes/i/ioannis/code/desihub/desi-photometry/validate-files -o $SCRATCH/lsdr9/fuji --specprod fuji --statistics --validate --mp 128
/global/homes/i/ioannis/code/desihub/desi-photometry/validate-files -o $SCRATCH/lsdr9/iron --specprod iron --statistics --validate --mp 128
/global/homes/i/ioannis/code/desihub/desi-photometry/validate-files -o $SCRATCH/lsdr9/guadalupe --specprod guadalupe --statistics --validate --mp 128

"""
import os, argparse, pdb
from glob import glob
import numpy as np
import fitsio
import multiprocessing

from astropy.table import Table

def _targets_one_tile(args):
    """Multiprocessing wrapper."""
    return targets_one_tile(*args) 

def targets_one_tile(tileid, obstile, pottile):
    """Check one file.

    """
    print('  Checking tile {}'.format(tileid))
    # Check that the set of targetids are unique.
    try:
        assert(len(obstile) == len(np.unique(obstile['TARGETID'])))
        assert(len(pottile) == len(np.unique(pottile['TARGETID'])))
        
    # Check that every target in the targetphot file is also in the
    # targetphot-potential file.
        K = np.isin(obstile['TARGETID'], pottile['TARGETID'], assume_unique=True)
        assert(len(K) == len(obstile['TARGETID']))
    except:
        print('  Problem with tile {}!'.format(tileid))
        #pdb.set_trace()        

    # Now, ensure that the data stored in the potential and observed catalogs
    # *for the same objects* are identical.
    #I = np.isin(pottile['TARGETID'], obstile['TARGETID'], assume_unique=True)
    I = np.hstack([np.where(tid == pottile['TARGETID'])[0] for tid in obstile['TARGETID']])
    pot = pottile[I]
    assert(np.all(pot['TARGETID'] == obstile['TARGETID']))
    for col in pot.colnames:
        diff = np.where(pot[col] != obstile[col])[0]
        if len(diff) > 0:
            J = ~np.isnan(obstile[col][diff]) # need to check nan separately
            if np.sum(J) > 0:
                diff = diff[J]
                print(col, pot[col][diff].data, obstile[col][diff].data)

def fileinfo(filelist, specprod, subdir):

    dsurvey = {
        'cmx': 'Commissioning Survey', 'special': 'Special targets',
        'sv1': 'Survey Validation 1', 'sv2': 'Survey Validation 2',
        'sv3': 'Survey Validation 3', 'main': 'Main Survey',
        '{}.fits'.format(specprod): 'Stack of the preceding XX catalogs.'}

    nrows, szs = [], []
    for onefile in filelist:
        # iron/main potential targets are split by healpix
        if type(onefile) == list:
            _nrows, _szs = [], []
            for _onefile in onefile:
                if os.path.isfile(_onefile):
                    _szs.append(os.stat(_onefile).st_size)
                    _nrows.append(fitsio.FITS(_onefile)[1].get_nrows())
                else:
                    print('Missing {}'.format(_onefile))
            szs.append(np.sum(_szs))
            nrows.append(np.sum(_nrows))
        else:
            if os.path.isfile(onefile):
                szs.append(os.stat(onefile).st_size)
                nrows.append(fitsio.FITS(onefile)[1].get_nrows())
            else:
                print('Missing {}'.format(onefile))
    szs = np.array(szs)
    nrows = np.array(nrows)
    if len(nrows) == 0:
        return

    #srt = np.argsort(nrows)
    srt = np.arange(len(nrows))

    print('| File Name | File Size | Number of Targets | Notes |')
    print('|-----------|:---------:|:-----------------:|-------|')
    for onefile, nrow, sz in zip(filelist[srt], nrows[srt], szs[srt]):
        if sz > 1024**2 and sz < 1024**3:
            sz /= 1024**2
            unit = 'MB'
            fmt = ''
        else:
            sz /= 1024**3
            unit = 'GB'

        if type(onefile) == list:
            # iron/main potential targets are a list
            #basefile = os.path.basename(onefile[0])
            survey = 'main'
            basefile = 'potential-targets/targetphot-potential-nside2-hp[0-9][0-9]-{}-{}.fits'.format(survey, specprod)
        else:
            basefile = os.path.basename(onefile)
            survey = basefile.split('-')[1]
            if survey == 'potential':
                survey = basefile.split('-')[2]
            basefile = os.path.join(subdir, basefile)
        notes = dsurvey[survey].replace('XX', str(len(filelist)-1))
            
        print('| {} | {:.3g} {} | {:,d} | {} |'.format(basefile, sz, unit, nrow, notes))

def main():

    p = argparse.ArgumentParser()
    p.add_argument('-o', '--outdir', type=str, required=True, help='output directory file')    
    p.add_argument('--specprod', type=str, required=True, choices=['fuji', 'iron', 'guadalupe'], help='output file prefix')
    p.add_argument('--mp', type=int, default=1, help='number of multiprocessing cores')
    p.add_argument('--statistics', action='store_true', help='Do file statistics.')
    p.add_argument('--validate', action='store_true', help='Validate the files.')
    
    args = p.parse_args()

    if args.specprod == 'fuji':
        surveys = ['cmx', 'special', 'sv1', 'sv2', 'sv3']
    elif args.specprod == 'iron':
        surveys = ['cmx', 'special', 'sv1', 'sv2', 'sv3', 'main']
    elif args.specprod == 'guadalupe':
        surveys = ['special', 'main']

    # Do statistics.
    if args.statistics:
        # targetphot files
        for targtype, targsuffix in zip(['observed', 'potential'], ['', '-potential']):
            print('targetphot - {} targets'.format(targtype))
            if args.specprod == 'iron':
                filelist = []
                for survey in surveys:
                    if survey == 'main' and targtype == 'potential':
                        mainlist = sorted(glob(os.path.join(args.outdir, '{}-targets'.format(targtype), 
                                                            'targetphot{}-nside2-hp??-{}-{}.fits'.format(targsuffix, survey, args.specprod))))
                        filelist.append(mainlist)
                    else:
                        filelist.append(os.path.join(args.outdir, '{}-targets'.format(targtype),
                                                     'targetphot{}-{}-{}.fits'.format(targsuffix, survey, args.specprod)))
                filelist.append(os.path.join(args.outdir, '{}-targets'.format(targtype),
                                             'targetphot{}-{}.fits'.format(targsuffix, args.specprod)))
            else:
                filelist = []
                for survey in surveys:
                    filelist.append(os.path.join(args.outdir, '{}-targets'.format(targtype),
                                                 'targetphot{}-{}-{}.fits'.format(targsuffix, survey, args.specprod)))
                filelist.append(os.path.join(args.outdir, '{}-targets'.format(targtype),
                                             'targetphot{}-{}.fits'.format(targsuffix, args.specprod)))
            #else:
            #    filelist = glob(os.path.join(args.outdir, '{}-targets'.format(targtype),
            #                                 'targetphot{}-*{}.fits'.format(targsuffix, args.specprod)))
            filelist = np.array(filelist, dtype=object)
            fileinfo(filelist, args.specprod, '{}-targets'.format(targtype))
            print()
        
        # tractorphot files
        for targtype, targsuffix in zip(['observed', 'potential'], ['', '-potential']):
            print('tractorphot - {} targets'.format(targtype))
            filelist = glob(os.path.join(args.outdir, '{}-targets'.format(targtype), 'tractorphot', 
                                         'tractorphot{}-nside4-hp???-{}.fits'.format(targsuffix, args.specprod)))
            nfiles = len(filelist)
            sz, nobj = [], []
            for onefile in filelist:
                sz.append(os.stat(onefile).st_size)
                nobj.append(fitsio.FITS(onefile)[1].get_nrows())
            sz = np.sum(sz)
            nobj = np.sum(nobj)
            if sz > 1024**2 and sz < 1024**3:
                sz /= 1024**2
                unit = 'MB'
                fmt = ''
            else:
                sz /= 1024**3
                unit = 'GB'
            print('| Data Release | Relative Location of *tractorphot* Files | Number of Files | Total Data Volume | Total Number of Objects |')
            print('|--------------|------------------------------------------|:---------------:|:-----------------:|:-----------------------:|')
            print('| {} | {}-targets/tractorphot/tractorphot{}-nside4-hp[0-9][0-9][0-9]-{}.fits | {} | {:.3g} {} | {:,d} |'.format(
                args.specprod, targtype, targsuffix, args.specprod, nfiles, sz, unit, nobj))
            print()
            
    # Validate files.
    if args.validate:
        for survey in surveys:
        #for survey in ['sv1']:
            print('Working on survey {}'.format(survey))
            obsfile = os.path.join(args.outdir, 'observed-targets', 'targetphot-{}-{}.fits'.format(survey, args.specprod))
            potfile = os.path.join(args.outdir, 'potential-targets', 'targetphot-potential-{}-{}.fits'.format(survey, args.specprod))
            #if not os.path.isfile(obsfile):
            #    continue
            
            obs = Table(fitsio.read(obsfile))
            print('Read {:,d} objects from {}'.format(len(obs), obsfile))
            pot = Table(fitsio.read(potfile))
            print('Read {:,d} objects from {}'.format(len(pot), potfile))

            #obs = obs[obs['TILEID'] == 80870]

            tileids = sorted(set(obs['TILEID']))
            print('Processing {} unique tiles'.format(len(tileids)))
            
            # Multiprocess over tiles
            mpargs = [[tileid, obs[obs['TILEID'] == tileid], pot[pot['TILEID'] == tileid]] for tileid in tileids]
                
            if args.mp > 1:
                with multiprocessing.Pool(args.mp) as P:
                    P.map(_targets_one_tile, mpargs)
            else:
                [targets_one_tile(*mparg) for mparg in mpargs]
        print()
            
if __name__ == '__main__':
    main()
